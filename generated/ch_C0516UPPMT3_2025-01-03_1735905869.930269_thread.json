{
  "id": "ch_C0516UPPMT3_2025-01-03_1735905869.930269_thread",
  "type": "channel",
  "channel_name": "aihub-feedback",
  "conversation_type": "thread",
  "participants": [
    "Kaustubh (KD)",
    "lydia",
    "Hamish"
  ],
  "messages": [
    {
      "sender": "Hamish",
      "user_id": "U06G3LGDBQU",
      "message": "Hey, for the extraction of an address on this document I really struggled to get the correct result (that worked consistently) using text extraction (project here (https://aihub.instabase.com/build/01942bd6-7e22-7fbf-8a6d-ec7f9b157965)).\n1. Things I tried\n    a. Various different prompts (I couldn't find a nice one that worked consistently)\n    b. Selection based prompt generation\n    c. Advanced model\n2. Other observations from text extraction\n    a. The associated confidence scores also didn't always seem a good match to the results\n    b. Long processing times (minutes to get result)\n3. As soon as I switched to reasoning I was able to get the result first time\n    a. Processing time was much faster\n    b. Results more consistent irrespective of standard model + prompting\nDo we know why this would be? Do we expect reasoning to provide better results on long docs?",
      "time": "04:04",
      "timestamp": "1735905869.930269",
      "is_reply": false
    },
    {
      "sender": "Kaustubh (KD)",
      "user_id": "U06G3LGPDFW",
      "message": "Is this specifically for the `Fund Prospectus` class? I see the following fields with reasoning:\n• Sub Funds\n    ◦ This is table/list output. For this @Hamish did you try list of objects? \n• Manager Address \n    ◦ This is interesting since it shows up on page 8 and 19 respectively for the 2 docs. I suspect that this a function of the documents being so large. @lydia anecdotally for the long docs I've seen reasoning act as a replacement for the other field types. Curious if you have thoughts here. cc: @Vishnu /@Nikolaos Kofinas as well\n• Fund Structure \n    ◦ This is a summary and so this makes sense as a reasoning prompt\nGenerally we know that source tracking needs to be improved and we have an initiative https://instabase.atlassian.net/browse/EPD-2893 (which I'm considering for Q1).",
      "time": "07:06",
      "timestamp": "1735916800.798119",
      "is_reply": true
    },
    {
      "sender": "Hamish",
      "user_id": "U06G3LGDBQU",
      "message": "This was only for the Manager Address field in this case :slightly_smiling_face:",
      "time": "07:09",
      "timestamp": "1735916993.852389",
      "is_reply": true
    },
    {
      "sender": "Kaustubh (KD)",
      "user_id": "U06G3LGPDFW",
      "message": "Yeah lets wait for the Model dev here. My understanding is the following (from @Vishnu a while ago :slightly_smiling_face: )\n\n• For short docs extraction and reasoning are kind of similar, but the system prompt for each is different. The reasoning prompt allows for more elaborate responses. Extraction tries to limit to just the tokens which fetch the exact data.\n• For long docs, the above applies, but also extraction follows map reduce and maps the query to every single chunk. Reasoning on the other hand will perform relevant chunk retrieval first, and then perform the query only once on the combined chunks.",
      "time": "07:12",
      "timestamp": "1735917140.515299",
      "is_reply": true
    },
    {
      "sender": "lydia",
      "user_id": "UJK4LKYSJ",
      "message": "Yes, that's right KD! cc @Nikolaos Kofinas something to think about for future quarters - I feel like more use cases have involved 100-300 page docs recently, and people are often reporting slow processing times for extraction fields in Build.",
      "time": "11:18",
      "timestamp": "1735931909.340869",
      "is_reply": true
    }
  ],
  "metadata": {
    "channel_id": "C0516UPPMT3",
    "channel_name": "aihub-feedback",
    "date_file": "2025-01-03.json",
    "message_count": 5,
    "start_time": "1735905869.930269",
    "end_time": "1735931909.340869",
    "is_thread": true
  }
}