{
  "id": "ch_C05L87V014J_2025-05-13_1747124932.216859_thread",
  "type": "channel",
  "channel_name": "ask-crafting",
  "conversation_type": "thread",
  "participants": [
    "jordy.vlan",
    "anshul.padhi"
  ],
  "messages": [
    {
      "sender": "anshul.padhi",
      "user_id": "U084V5XTMFT",
      "message": "error in the model-service\n\n`ERROR: failed to solve: process \"/bin/sh -c PYTHONPATH=/model-service/py python3 instabase/ibllm/model/download_tiktoken_encodings.py --target-dir=/model-service/py/tiktoken_encodings\" did not complete successfully: exit code: 1`",
      "time": "01:28",
      "timestamp": "1747124932.216859",
      "is_reply": false
    },
    {
      "sender": "jordy.vlan",
      "user_id": "U072CDMB4N8",
      "message": "This is likely sthin that was done for running OpenAI models on-prem / airgapped envs. Unsure why this tiktoken encoding would need to be cached for standard envs :slightly_smiling_face:",
      "time": "01:37",
      "timestamp": "1747125421.706989",
      "is_reply": true
    },
    {
      "sender": "anshul.padhi",
      "user_id": "U084V5XTMFT",
      "message": "better performance so should be fine ig. Also this is resolved, it was linked to another bug in the config.py file",
      "time": "01:52",
      "timestamp": "1747126363.281659",
      "is_reply": true
    }
  ],
  "metadata": {
    "channel_id": "C05L87V014J",
    "channel_name": "ask-crafting",
    "date_file": "2025-05-13.json",
    "message_count": 3,
    "start_time": "1747124932.216859",
    "end_time": "1747126363.281659",
    "is_thread": true
  }
}