{
  "id": "ch_C0516UPPMT3_2023-08-17_1692266191.601829_conversation",
  "type": "channel",
  "channel_name": "aihub-feedback",
  "conversation_type": "conversation",
  "participants": [
    "Varun Jain"
  ],
  "messages": [
    {
      "sender": "Varun Jain",
      "user_id": "U019KDMQL14",
      "message": "Team, we got the following feedback from BRM Labs (a paid user on AI Hub)\n> 1. Extraction quality is on par if not better than the popular LLMs today\n> 2. There’s less control in the output format than we’d like. \n>     a. It’s hard to get a consistent NULL response (e.g. $NULL), or a consistent boolean response. \n>     b. Date formats are hard to structure the return in a parseable ISO YYYY-MM-DD format which GPT has historically adhered to very well. \n>     c. Sometimes responses will be more “human-like”, e.g. “There is no XYZ found in the document” when we’ve instructed to return NULL in such cases \n> 3. It feels like the complex prompt performs worse than a standard prompt. The response format has much higher variance with the complex prompt. \n@Eric Han @lydia @Bastiane - internal users have also reported similar issues. Is this linked to how we wrap / modify prompts?",
      "time": "02:56",
      "timestamp": "1692266191.601829",
      "is_reply": false
    }
  ],
  "metadata": {
    "channel_id": "C0516UPPMT3",
    "channel_name": "aihub-feedback",
    "date_file": "2023-08-17.json",
    "message_count": 1,
    "start_time": "1692266191.601829",
    "end_time": "1692266191.601829",
    "is_thread": false
  }
}