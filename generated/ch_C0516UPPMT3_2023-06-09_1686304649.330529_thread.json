{
  "id": "ch_C0516UPPMT3_2023-06-09_1686304649.330529_thread",
  "type": "channel",
  "channel_name": "aihub-feedback",
  "conversation_type": "thread",
  "participants": [
    "Fabien Ribert",
    "vineeth",
    "Matt Weaver"
  ],
  "messages": [
    {
      "sender": "Fabien Ribert",
      "user_id": "U02T6QZ97BL",
      "message": "Hi, it seems AI hub is very slow and can't give an answer",
      "time": "02:57",
      "timestamp": "1686304649.330529",
      "is_reply": false
    },
    {
      "sender": "vineeth",
      "user_id": "U0175SZ13F0",
      "message": "Could you try default model? Looks like there are a lot of tokens to be generated for your query and it is timing out for advanced model since latency is a bit high for advanced model. Default model should go through ideally",
      "time": "03:02",
      "timestamp": "1686304947.016879",
      "is_reply": true
    },
    {
      "sender": "Matt Weaver",
      "user_id": "U01B8GFNUAC",
      "message": "Thinking of the user experience, how do we improve this for other users who try something similar?",
      "time": "03:31",
      "timestamp": "1686306664.880699",
      "is_reply": true
    },
    {
      "sender": "vineeth",
      "user_id": "U0175SZ13F0",
      "message": "Maybe we can limit the response tokens for advanced model, infact all these issues will be solved when we complete our streaming response dev efforts cc: @Rakesh",
      "time": "03:33",
      "timestamp": "1686306836.274369",
      "is_reply": true
    },
    {
      "sender": "vineeth",
      "user_id": "U0175SZ13F0",
      "message": "So the answer would be streamed word by word (actually token by token), so there wont be any timeout issues",
      "time": "03:34",
      "timestamp": "1686306879.188219",
      "is_reply": true
    },
    {
      "sender": "vineeth",
      "user_id": "U0175SZ13F0",
      "message": "Just like ChatGPT :wink:",
      "time": "03:35",
      "timestamp": "1686306919.295909",
      "is_reply": true
    }
  ],
  "metadata": {
    "channel_id": "C0516UPPMT3",
    "channel_name": "aihub-feedback",
    "date_file": "2023-06-09.json",
    "message_count": 6,
    "start_time": "1686304649.330529",
    "end_time": "1686306919.295909",
    "is_thread": true
  }
}