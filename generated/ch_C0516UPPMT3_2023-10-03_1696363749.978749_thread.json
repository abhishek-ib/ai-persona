{
  "id": "ch_C0516UPPMT3_2023-10-03_1696363749.978749_thread",
  "type": "channel",
  "channel_name": "aihub-feedback",
  "conversation_type": "thread",
  "participants": [
    "Dale DeLoy"
  ],
  "messages": [
    {
      "sender": "Dale DeLoy",
      "user_id": "U01T2LEP1FF",
      "message": "Creating a thread to carry on the discussion around Court Orders for Santander Brazil @Kerry @fernando.piazza.ctr @ChrisM",
      "time": "13:09",
      "timestamp": "1696363749.978749",
      "is_reply": false
    },
    {
      "sender": "Dale DeLoy",
      "user_id": "U01T2LEP1FF",
      "message": "The environment we are using is: https://court-orders.internal.instabase.com",
      "time": "13:09",
      "timestamp": "1696363795.018759",
      "is_reply": true
    },
    {
      "sender": "Dale DeLoy",
      "user_id": "U01T2LEP1FF",
      "message": "We are seeing a few problems:\n1. Hitting rate limit with GPT-4\n2. Hitting file size limits that are not well addressed through splitting\n3. Wrong error shown through refiner (all errors showing provenance tracking error)\nInitial task is to limit the parallel document execution to reduce the potential of hitting the GPT-4 limit\nAdditionally review opportunities to batch prompts within refiner and then parse results",
      "time": "13:18",
      "timestamp": "1696364282.861329",
      "is_reply": true
    },
    {
      "sender": "Dale DeLoy",
      "user_id": "U01T2LEP1FF",
      "message": "Additionally we are seeing larger files seem to get processed via OCR and then throwing errors in different portions of the flow.  Attached is a log of the issues",
      "time": "13:24",
      "timestamp": "1696364645.716039",
      "is_reply": true
    }
  ],
  "metadata": {
    "channel_id": "C0516UPPMT3",
    "channel_name": "aihub-feedback",
    "date_file": "2023-10-03.json",
    "message_count": 4,
    "start_time": "1696363749.978749",
    "end_time": "1696364645.716039",
    "is_thread": true
  }
}