{
  "id": "ch_C0516UPPMT3_2023-08-21_1692631305.941789_thread",
  "type": "channel",
  "channel_name": "aihub-feedback",
  "conversation_type": "thread",
  "participants": [
    "joshbronko",
    "Dale DeLoy"
  ],
  "messages": [
    {
      "sender": "Dale DeLoy",
      "user_id": "U01T2LEP1FF",
      "message": "Is there a plan to submit record level documents to the LLM instead of full documents when using a split classifier in a flow.  This is becoming critical for several applications with long documents.",
      "time": "08:21",
      "timestamp": "1692631305.941789",
      "is_reply": false
    },
    {
      "sender": "joshbronko",
      "user_id": "U031T0PNLUS",
      "message": "with Refiner LLM you can do this. Or are you asking in the context of AIHUB directly?",
      "time": "08:29",
      "timestamp": "1692631772.345889",
      "is_reply": true
    },
    {
      "sender": "Dale DeLoy",
      "user_id": "U01T2LEP1FF",
      "message": "Will need to see how to make this happen, my understanding is that even if you have broken a long document into several records, the submission to the LLM is still sending the full document and not the record subset.  Will try to run some tests today using ib_llm_tools to see how it goes.",
      "time": "08:38",
      "timestamp": "1692632282.405209",
      "is_reply": true
    }
  ],
  "metadata": {
    "channel_id": "C0516UPPMT3",
    "channel_name": "aihub-feedback",
    "date_file": "2023-08-21.json",
    "message_count": 3,
    "start_time": "1692631305.941789",
    "end_time": "1692632282.405209",
    "is_thread": true
  }
}