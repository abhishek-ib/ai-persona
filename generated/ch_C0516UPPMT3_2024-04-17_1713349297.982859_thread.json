{
  "id": "ch_C0516UPPMT3_2024-04-17_1713349297.982859_thread",
  "type": "channel",
  "channel_name": "aihub-feedback",
  "conversation_type": "thread",
  "participants": [
    "Bastiane",
    "Kaustubh (KD)",
    "Jianqi Xing",
    "Hamish"
  ],
  "messages": [
    {
      "sender": "Hamish",
      "user_id": "U06G3LGDBQU",
      "message": "Hey team, I've been playing around with prompt generated validations - very cool feature that I'm excited to see in the platform! I have a couple of feedback points on how I found it though:\n1. I hit errors a lot when writing prompts (see example below). Am I structuring these prompts incorrectly? \n2. I found it confusing when the extracted fields dropped down as options when writing the prompts. Once you select a field e.g. Account Number, I think it should be in a different font to the rest of the prompt, a bit like in Slack e.g. \"`Account Number` should be...\"\n    a. Since I access the validation for a specific field through the UI by selecting to edit that field, I also found it confusing that I didn't have guard rails to only create validations for the field I had chosen to edit.\n3. I thought the examples view could be improved. A green tick is placed beside examples which match the expected result. Initially I didn't know if the green ticks were for examples that returned a PASS result, or for examples that were a match to the expected result. I think it would be more effective to have something like the results table (see below) with headers: test case, expected result, actual result, pass/fail\n4. It wasn't clear to me how I should change the generated validation code. Is it by altering my initial prompt (resulted in an error for me)? Does adding test cases change the code or are these just for me to test the generated code better (no change, just test case failure for me)?",
      "time": "03:21",
      "timestamp": "1713349297.982859",
      "is_reply": false
    },
    {
      "sender": "Bastiane",
      "user_id": "U046R81BMM4",
      "message": "Thanks for the feedback! cc @Elan Sharony for the error messages. We are looking into improving the UX including the field dropdown and providing more guidance on iteration (you can change your prompt or test case to do so) cc @Jianqi Xing @andy @Kaustubh (KD)",
      "time": "09:03",
      "timestamp": "1713369833.364079",
      "is_reply": true
    },
    {
      "sender": "Kaustubh (KD)",
      "user_id": "U06G3LGPDFW",
      "message": "Super helpful feedback thanks @Hamish!",
      "time": "09:27",
      "timestamp": "1713371254.821209",
      "is_reply": true
    },
    {
      "sender": "Jianqi Xing",
      "user_id": "U02T6QZ7858",
      "message": "Thanks for the feedback. We can look into this. @Natasha I believe some of our latest iterations have addressed (2). We can look into (3). (1) and (4) are more technical than design in my opinions but I can be wrong @Elan Sharony.",
      "time": "10:05",
      "timestamp": "1713373520.247859",
      "is_reply": true
    }
  ],
  "metadata": {
    "channel_id": "C0516UPPMT3",
    "channel_name": "aihub-feedback",
    "date_file": "2024-04-17.json",
    "message_count": 4,
    "start_time": "1713349297.982859",
    "end_time": "1713373520.247859",
    "is_thread": true
  }
}