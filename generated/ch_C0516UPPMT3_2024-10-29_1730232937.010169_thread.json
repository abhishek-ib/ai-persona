{
  "id": "ch_C0516UPPMT3_2024-10-29_1730232937.010169_thread",
  "type": "channel",
  "channel_name": "aihub-feedback",
  "conversation_type": "thread",
  "participants": [
    "david.lee",
    "jordy.vlan",
    "andy",
    "Kaustubh (KD)",
    "lydia"
  ],
  "messages": [
    {
      "sender": "david.lee",
      "user_id": "U07JFN3TPAA",
      "message": "Also on visual reasoning, I used some medical diagrams to see if it can help produce summaries from them. Decided to do this because a conversation with Vatica health last week (CC @louisa.gould) revealed an interesting use case we could help tackle:\n1. They are looking for a tool to scan through hundreds of pages of medical records and identify diagnoses and related proof of evidence.  A part of that is being able to \"transcribe\" from visual diagrams into words, since images can't be included in their final report.\n2. When single-page sample body charts are uploaded, the descriptions seem accurate and relevant, recognizing highlighted areas in the diagrams and synthesizing information to produce summaries!\n3. It failed to identify a diagram in the 243-page document (3rd ss). I feel that our differentiator in using visual models should include detecting specific visual objects from long documents and being able to reason with them, not just being able to reason with them when uploaded separately\n    a. When I exported just the one page containing the diagram into a PDF and uploaded it, the model was able to pick up on it and produce a reasonable summary (6th SS).\n    b. I was able to see similar diagrams detected in the 4th & 5th SSs in a different doc, that was 87 pages long\n4. I tried to pick up on the car diagram (last SS) and it didn't work for either model.\nOverall, I think this could help our solution pick up on even more unstructured data elements. Happy to provide more feedback!",
      "time": "13:15",
      "timestamp": "1730232937.010169",
      "is_reply": false
    },
    {
      "sender": "andy",
      "user_id": "U0130FUMPN3",
      "message": "CC: @lydia",
      "time": "13:26",
      "timestamp": "1730233566.735709",
      "is_reply": true
    },
    {
      "sender": "lydia",
      "user_id": "UJK4LKYSJ",
      "message": "Added this example to https://instabase.atlassian.net/browse/EPD-2365\n\ncc @jordy.vlan @Kaustubh (KD) as an example where users may want to reference visual elements with no text anchors.",
      "time": "13:41",
      "timestamp": "1730234469.091909",
      "is_reply": true
    },
    {
      "sender": "jordy.vlan",
      "user_id": "U072CDMB4N8",
      "message": "Thanks! Exactly, this is a great proof point for visual retrieval :)",
      "time": "13:47",
      "timestamp": "1730234878.248949",
      "is_reply": true
    },
    {
      "sender": "Kaustubh (KD)",
      "user_id": "U06G3LGPDFW",
      "message": "Love the feedback @david.lee keep it coming  :slightly_smiling_face:",
      "time": "14:10",
      "timestamp": "1730236251.840129",
      "is_reply": true
    },
    {
      "sender": "jordy.vlan",
      "user_id": "U072CDMB4N8",
      "message": "@david.lee for the last screenshot I see that you used document reasoning instead?",
      "time": "14:13",
      "timestamp": "1730236386.518829",
      "is_reply": true
    },
    {
      "sender": "david.lee",
      "user_id": "U07JFN3TPAA",
      "message": "@jordy.vlan Ha yeah I don't know why. Tried visual reasoning and got the same response",
      "time": "14:15",
      "timestamp": "1730236502.684349",
      "is_reply": true
    }
  ],
  "metadata": {
    "channel_id": "C0516UPPMT3",
    "channel_name": "aihub-feedback",
    "date_file": "2024-10-29.json",
    "message_count": 7,
    "start_time": "1730232937.010169",
    "end_time": "1730236502.684349",
    "is_thread": true
  }
}