{
  "id": "ch_C0516UPPMT3_2023-09-14_1694692600.039719_thread",
  "type": "channel",
  "channel_name": "aihub-feedback",
  "conversation_type": "thread",
  "participants": [
    "Sławek Biel",
    "Rahul Rawal"
  ],
  "messages": [
    {
      "sender": "Rahul Rawal",
      "user_id": "U01J0N3UV7E",
      "message": "@Sławek Biel, any updates? I am facing similar error: `openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 6331 tokens. Please reduce the length of the messages.\"`\nQuery was: `What's this document about?`",
      "time": "04:56",
      "timestamp": "1694692600.039719",
      "is_reply": false
    },
    {
      "sender": "Sławek Biel",
      "user_id": "U03E1LBTKV2",
      "message": "I’m working on the PR that fixes it. I’ll try to finish it today",
      "time": "04:57",
      "timestamp": "1694692658.418359",
      "is_reply": true
    }
  ],
  "metadata": {
    "channel_id": "C0516UPPMT3",
    "channel_name": "aihub-feedback",
    "date_file": "2023-09-14.json",
    "message_count": 2,
    "start_time": "1694692600.039719",
    "end_time": "1694692658.418359",
    "is_thread": true
  }
}