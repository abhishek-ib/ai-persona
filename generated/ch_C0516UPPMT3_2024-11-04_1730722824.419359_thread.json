{
  "id": "ch_C0516UPPMT3_2024-11-04_1730722824.419359_thread",
  "type": "channel",
  "channel_name": "aihub-feedback",
  "conversation_type": "thread",
  "participants": [
    "Jasper",
    "Hari",
    "fernando.piazza.ctr",
    "Varun K V"
  ],
  "messages": [
    {
      "sender": "fernando.piazza.ctr",
      "user_id": "U05KP13EJ8L",
      "message": "Hello. Do we have plans to add the fuzzywuzzy library to AI Hub? The idea is to compare the result returned by the LLM with a list of items, to find the 5 or 10 items which are more similar. That would be a second step verification, after we ask the LLM to return the more similar item. The intention is to use it in medical orders, where we need to get the right exam from a list of around 5,000 possible exams. If we can't get an exact match, we should be able to show the best candidates from the list to the analyst, who would pick the best one.",
      "time": "04:20",
      "timestamp": "1730722824.419359",
      "is_reply": false
    },
    {
      "sender": "Hari",
      "user_id": "UCX3XL72Q",
      "message": "@fernando.piazza.ctr LLM should be able to do it very well! We use LLM in similar scenarios already, for example all our benchmark scores are generated by comparing the expected vs response received, golden comparisons etc..",
      "time": "05:04",
      "timestamp": "1730725454.495959",
      "is_reply": true
    },
    {
      "sender": "Jasper",
      "user_id": "U02KPTJGSCC",
      "message": "@Hari I would be curious to understand your best practice for this type of scenario. For a small list of items we can just include them in a cleaning prompt. But for a large list like 5000 exams in Fernando's case that would not fit into the context window of the cleaning prompt.",
      "time": "05:33",
      "timestamp": "1730727238.802309",
      "is_reply": true
    },
    {
      "sender": "Varun K V",
      "user_id": "U038G74EBT2",
      "message": "If context window has limitations and if we need a custom implementation,\ndifflib from SequenceMatcher is supported in IB platform to get the functionality of fuzzywuzzy, I believe it should work in AI-Hub as well.\n@fernando.piazza.ctr, We can have a quick call for the implementation of this library for the usecase.",
      "time": "06:11",
      "timestamp": "1730729478.833199",
      "is_reply": true
    },
    {
      "sender": "fernando.piazza.ctr",
      "user_id": "U05KP13EJ8L",
      "message": "This is the context. The lab has a list of 5,400 exams. We read a medical order, and we need to extract all exams in it, but they must belong to the list, to be valid and type into the system. We ask the LLM: \"What are the exams asked in this medical order? Select the items from this list that are more similar. <Here we include the long list>\" We get a list, but not all items match, usually less than half. In this case, how do we pick the right exams from the list? Perhaps using a similarity score to pick the one that is more similar, or show the 5 best to the analyst? With medical exams, we can't go wrong, so we need to select a valid exam.",
      "time": "11:49",
      "timestamp": "1730749752.132319",
      "is_reply": true
    },
    {
      "sender": "Jasper",
      "user_id": "U02KPTJGSCC",
      "message": "Weâ€˜ve had this request many times now in the past and we came up with several different approaches.\nIt would be good to create a decision tree on when to use which approach for the future.",
      "time": "13:15",
      "timestamp": "1730754933.588929",
      "is_reply": true
    }
  ],
  "metadata": {
    "channel_id": "C0516UPPMT3",
    "channel_name": "aihub-feedback",
    "date_file": "2024-11-04.json",
    "message_count": 6,
    "start_time": "1730722824.419359",
    "end_time": "1730754933.588929",
    "is_thread": true
  }
}