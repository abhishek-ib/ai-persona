{
  "id": "ch_C0516UPPMT3_2024-04-02_1712063193.481349_thread",
  "type": "channel",
  "channel_name": "aihub-feedback",
  "conversation_type": "thread",
  "participants": [
    "ChrisM",
    "avi",
    "Hari",
    "fernando.piazza.ctr"
  ],
  "messages": [
    {
      "sender": "fernando.piazza.ctr",
      "user_id": "U05KP13EJ8L",
      "message": "Hi team. We have been asked for quick answers in the Chatbot. The expectation people have comes from ChatGPT, where they ask something and get an answer in a few seconds. Of course, in our case, we have to read many documents to return with an answer, and that's way faster than having people doing it. But there is an opportunity here. Microsoft has been criticized by the clients for being much slower than OpenAI. That's the reason. If we can take advantage of this, there may be a great opportunity. Can we, somehow, have our system reading a set of documents once, and storing their info in some kind of knowledge base that would return quicker answers? The intention, and the interest is to have Instabase Chatbot in between another chatbot (digital channel) and the systems of record. One example: Build a chatbot that will allow insurance brokers to ask questions about the insurance operator's policies (some 50 documets that don't change often), and get the answer in a few seconds. Any insights on this?",
      "time": "06:06",
      "timestamp": "1712063193.481349",
      "is_reply": false
    },
    {
      "sender": "Hari",
      "user_id": "UCX3XL72Q",
      "message": "@fernando.piazza.ctr We are looking into different methods to speed up Chatbot response! It’s work in progress, no definitive timeline or number commitment yet. But we will update to everyone on the progress here. In the meantime if you can engage the customer to test out the accuracy that will be beneficial. \n\nCc: @avi @vineeth",
      "time": "06:25",
      "timestamp": "1712064355.827869",
      "is_reply": true
    },
    {
      "sender": "avi",
      "user_id": "U0477QPPM17",
      "message": "Thanks @fernando.piazza.ctr. I'm curious which customers were asking for quicker answers? Have they already tried chatbots and if so, what's the usecase? How was their experience aside from speed (accuracy, UX, etc.)\n\nWe are actively thinking about the insurance operator scenario, here's a sample chatbot built on AXA's docs - https://aihub.instabase.com/hub/apps/a1546a31-555d-4d9e-bdb4-b5ad55219ebc",
      "time": "09:17",
      "timestamp": "1712074667.778879",
      "is_reply": true
    },
    {
      "sender": "fernando.piazza.ctr",
      "user_id": "U05KP13EJ8L",
      "message": "Hi @Hari, @avi. The client is GNP Insurance. The test with the Chatbot response time is important for the decision on a project with us. They already tested the accuracy, and it's fine. As the chatbot will intermediate queries from brokers, it needs to answer quickly (in a matter of seconds). They need to process about 42 documents with some 70 pages each. Those documents don't change often, so I wondered if we can somehow improve the speed in those cases (static documents).",
      "time": "09:56",
      "timestamp": "1712077012.462229",
      "is_reply": true
    },
    {
      "sender": "avi",
      "user_id": "U0477QPPM17",
      "message": "Awesome, this helps a lot! @fernando.piazza.ctr creating a PFR for this, we can followup there and find a way to win this customer :muscle::skin-tone-4:",
      "time": "10:27",
      "timestamp": "1712078830.142389",
      "is_reply": true
    },
    {
      "sender": "avi",
      "user_id": "U0477QPPM17",
      "message": "Few questions to help us understand the scenario.\n• What is the main driver for faster responses? Is it for better UX, or required to be under a certain latency for a business process?\n• Does the customer already have AI Hub commercial?\n• Are they ok with the pricing for chatbots (rough $2 per query)? If not, we can discuss this.\n• If we can get quicker answers, how sure are we that they will sign an AI Hub contract in the near future?",
      "time": "10:30",
      "timestamp": "1712079052.491829",
      "is_reply": true
    },
    {
      "sender": "ChrisM",
      "user_id": "U03AB9GNNAH",
      "message": "This has been a question asked by a couple of other partners who I have demoed the chatbot feature to. Like a multi-step query in Converse, it usually takes 45-60 seconds to complete a query. When you're doing a demo, you can talk through this and explain what it is doing, but when you are in a production situation (and have noone to talk to :wink: ), it can feel like a very long time. I recently tested a tool called Chatbase (https://www.chatbase.co/), and they create RAG based chatbots from documents or URLs and their responses were almost instantaneous.\n\nI am pursuing other ISVs to embed chatbots in their UI for their users, and I latency is a concern. I'm glad to hear we are working on this.",
      "time": "12:11",
      "timestamp": "1712085101.776309",
      "is_reply": true
    },
    {
      "sender": "avi",
      "user_id": "U0477QPPM17",
      "message": "Ack, that makes sense Chris. A lot of other RAG chatbots (including Chatbase) are instantaneous, but they don't follow a multi-step retrieval process (query rewriting, multiple RAG calls, self-critique). This leads to further latency for us, but also higher quality answers. Are you seeing cases where the customer is equally happy with answers from other chatbots that are instantaneous?",
      "time": "23:06",
      "timestamp": "1712124415.389589",
      "is_reply": true
    }
  ],
  "metadata": {
    "channel_id": "C0516UPPMT3",
    "channel_name": "aihub-feedback",
    "date_file": "2024-04-02.json",
    "message_count": 8,
    "start_time": "1712063193.481349",
    "end_time": "1712124415.389589",
    "is_thread": true
  }
}