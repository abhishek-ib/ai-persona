{
  "id": "ch_C06FA6A23_2019-12-02_1575302578.071000_thread",
  "type": "channel",
  "channel_name": "discuss-engineering",
  "conversation_type": "thread",
  "participants": [
    "Kerry",
    "Aaron Vontell",
    "Ted"
  ],
  "messages": [
    {
      "sender": "Aaron Vontell",
      "user_id": "UCWNLU6CB",
      "message": "Hey I need some brainstorming / help for writing a flow that does the following:\n1. Read in multiple CSV files\n2. Split by new lines (basically each record is an entry in the CSV)\n3. Output each record as a file\nSteps 1 and 2 are easy, and step 3 is possibly solved by a merge files step, but I need to breakup that out.ibocr from merge files into multiple files, one for each record",
      "time": "08:02",
      "timestamp": "1575302578.071000",
      "is_reply": false
    },
    {
      "sender": "Ted",
      "user_id": "UAEM2MEGJ",
      "message": "Cc @dlluncor @nakul a section which covers this sort of template scenario would be bonkers valuable for POC training.",
      "time": "08:07",
      "timestamp": "1575302879.072600",
      "is_reply": true
    },
    {
      "sender": "Kerry",
      "user_id": "UCX3VGDJR",
      "message": "You should be able to do this using\n1. Process file to read multiple CSV \n2. Map record - split by new line \n3. Apply UDF to write files in any format",
      "time": "09:51",
      "timestamp": "1575309072.073400",
      "is_reply": true
    },
    {
      "sender": "Aaron Vontell",
      "user_id": "UCWNLU6CB",
      "message": "^ all done, yeah thatâ€™s what I did XD",
      "time": "09:51",
      "timestamp": "1575309087.073600",
      "is_reply": true
    },
    {
      "sender": "Kerry",
      "user_id": "UCX3VGDJR",
      "message": "haha nice :thumbsup:",
      "time": "09:51",
      "timestamp": "1575309114.073800",
      "is_reply": true
    }
  ],
  "metadata": {
    "channel_id": "C06FA6A23",
    "channel_name": "discuss-engineering",
    "date_file": "2019-12-02.json",
    "message_count": 5,
    "start_time": "1575302578.071000",
    "end_time": "1575309114.073800",
    "is_thread": true
  }
}