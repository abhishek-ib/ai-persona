{
  "id": "ch_C0516UPPMT3_2025-05-01_1746099393.612819_thread",
  "type": "channel",
  "channel_name": "aihub-feedback",
  "conversation_type": "thread",
  "participants": [
    "Chuba"
  ],
  "messages": [
    {
      "sender": "Chuba",
      "user_id": "U03DZA2HUFM",
      "message": "Logs are from consolidated export by label, so they are really long and not necessarily structured in a sensible fashion. The logs I was discussing look like this\n```level=ERROR time=2025-04-25 14:41:26,934 msg=\"Failed model inference: Model service error: \" model_id=\"ModelID(name=ibllm, version=2.1.0, is_project_model=False)\" num_inputs=\"1\" status=\"fail\" job_id=\"cdcf94c7-8c01-4d7f-85af-4ab2750322b6\" external_model=\"True\" duration_secs=\"799.0029771327972\" path=\"/model-service/py/instabase/model_service/handler.py:76\" process=\"MainProcess\" thread=\"ThreadPoolExecutor-3_3\" trace_id=\"32347baef1de6ec7\"```\nafter eliminating these messages with the recent upgrade to their Bedrock models, I don’t think they’re seeing the NoneType issue anymore, but also the upgrade could have included various other fixes at the same time that may have resolved it",
      "time": "04:36",
      "timestamp": "1746099393.612819",
      "is_reply": false
    }
  ],
  "metadata": {
    "channel_id": "C0516UPPMT3",
    "channel_name": "aihub-feedback",
    "date_file": "2025-05-01.json",
    "message_count": 1,
    "start_time": "1746099393.612819",
    "end_time": "1746099393.612819",
    "is_thread": true
  }
}