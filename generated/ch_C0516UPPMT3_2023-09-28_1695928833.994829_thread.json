{
  "id": "ch_C0516UPPMT3_2023-09-28_1695928833.994829_thread",
  "type": "channel",
  "channel_name": "aihub-feedback",
  "conversation_type": "thread",
  "participants": [
    "Bastiane",
    "Kerry",
    "Eric Han",
    "fernando.piazza.ctr",
    "Will McDermott",
    "Tom",
    "ChrisM",
    "Bas"
  ],
  "messages": [
    {
      "sender": "Will McDermott",
      "user_id": "U03DJMXCNCF",
      "message": "Hi team, trying to upload a large loan file (2,000 pages, 315MB) to Converse for a potential customer. Converse is saying >50MB is unsupported. Any recommendations?",
      "time": "12:20",
      "timestamp": "1695928833.994829",
      "is_reply": false
    },
    {
      "sender": "Tom",
      "user_id": "UUEDM4T9R",
      "message": "This is for an active customer deal so any workarounds appreciated",
      "time": "12:26",
      "timestamp": "1695929197.909139",
      "is_reply": true
    },
    {
      "sender": "Bas",
      "user_id": "U0290LSC5QA",
      "message": "I thought that part of what we did was auto splitting and stitching to deal with long docs. Interesting to learn the limits of that",
      "time": "12:49",
      "timestamp": "1695930599.581669",
      "is_reply": true
    },
    {
      "sender": "ChrisM",
      "user_id": "U03AB9GNNAH",
      "message": "We have an opportunity in LATAM with similar issues.",
      "time": "13:03",
      "timestamp": "1695931433.985029",
      "is_reply": true
    },
    {
      "sender": "Kerry",
      "user_id": "UCX3VGDJR",
      "message": "First of all, like it says in the UI, this is not supported. This file is.... longer than an average Bible I think.\n\nWhat kind of questions / prompts we want to ask for this huge file?\n\nCan we manually break this large file down to multiple smaller files and upload the smaller files? If there're any meaningful breakdowns using table of content or sections. Ideally the file names can tell the user what file they should select based on their questions.\n\nFor example, break the bible in to new and old testament, and ask questions to them separately....",
      "time": "13:21",
      "timestamp": "1695932482.817889",
      "is_reply": true
    },
    {
      "sender": "ChrisM",
      "user_id": "U03AB9GNNAH",
      "message": "For the LATAM use case, it is 1000 page court orders received by a bank.",
      "time": "13:22",
      "timestamp": "1695932572.085839",
      "is_reply": true
    },
    {
      "sender": "Bas",
      "user_id": "U0290LSC5QA",
      "message": "Could be interesting to see if there is a way to do this cutting as part of the same experience on AI Hub",
      "time": "13:22",
      "timestamp": "1695932579.190129",
      "is_reply": true
    },
    {
      "sender": "Bas",
      "user_id": "U0290LSC5QA",
      "message": "Like a simplified split classifier",
      "time": "13:23",
      "timestamp": "1695932638.077939",
      "is_reply": true
    },
    {
      "sender": "Kerry",
      "user_id": "UCX3VGDJR",
      "message": "Yeah that's a good idea -- we can put that into our backlog. that's why i ask what kind of document and what kind of question we are planning to ask. Different approaches to do if the 1000-page file is 1000 1-page court orders vs one giant 1000-page order\n\nAlso the type of questions is important too",
      "time": "13:27",
      "timestamp": "1695932844.568949",
      "is_reply": true
    },
    {
      "sender": "Bas",
      "user_id": "U0290LSC5QA",
      "message": "Yeah, I think it would be practical. Nearly all information is organized in some way (chapters, sections etc.). 1000 page long info as one long piece is more like a machine output file which is not what IB is meant for anyway",
      "time": "13:29",
      "timestamp": "1695932989.241329",
      "is_reply": true
    },
    {
      "sender": "ChrisM",
      "user_id": "U03AB9GNNAH",
      "message": "We're working to get samples for the LATAM bank (Santander) and can share more about the prompts/questions we need to answer soon.",
      "time": "13:31",
      "timestamp": "1695933081.261499",
      "is_reply": true
    },
    {
      "sender": "fernando.piazza.ctr",
      "user_id": "U05KP13EJ8L",
      "message": "Hi @Kerry. The documents we'll receive from the bank are legal actions, court orders and contracts. The bank told us that it's common to see 1,000+ pages in some of them, as they're a collection of text, scanned evidences, IDs, police reports, certificates, tables, notary files, and other things, all packed in a single PDF. I have some of those with 500+ pages already. Let me know if you want to see some of them. I can't share them here, as they're highly sensitive.",
      "time": "13:49",
      "timestamp": "1695934166.694169",
      "is_reply": true
    },
    {
      "sender": "Will McDermott",
      "user_id": "U03DJMXCNCF",
      "message": "Thanks for the recommendations @Kerry! Similarly to the above use-case, long jumbo loan files contain a lot of different documents - applications, proof of incomes docs (bank statements, brokerage statements, paystubs, etc), deed, social security card, IDs. Most of the pages don't need to be extracted from, so classifying them out would be valuable, or interrogating the entire packet to try to just extract proof of income (this is what I was attempting to do in Ai Hub just now). It would be challenging splitting off of rules because each doc type is highly variable in length",
      "time": "14:02",
      "timestamp": "1695934953.494099",
      "is_reply": true
    },
    {
      "sender": "Eric Han",
      "user_id": "UKPHNU5QE",
      "message": "@lydia and @Bastiane this is a good place to collect split classification examples.\n\nas Kerry mentioned above, if we can get these requests earlier in the cycle itâ€™ll help us greatly to prioritize and ship these features for AIHub.\n\nAs for a workaround, we might need to fall back to enterprise platform if we want to sell to this customer right this moment",
      "time": "15:02",
      "timestamp": "1695938555.669359",
      "is_reply": true
    },
    {
      "sender": "Bastiane",
      "user_id": "U046R81BMM4",
      "message": "@Will McDermott can you please share the sample doc with us? We will look into it as we are working on split classification",
      "time": "15:22",
      "timestamp": "1695939765.715639",
      "is_reply": true
    },
    {
      "sender": "Will McDermott",
      "user_id": "U03DJMXCNCF",
      "message": "Awesome @Bastiane thank you! To be fair - this is a super complex packet. Think we're going to have to whittle down the problem more before attacking this (even if we used the Enterprise platform).",
      "time": "16:51",
      "timestamp": "1695945071.389759",
      "is_reply": true
    }
  ],
  "metadata": {
    "channel_id": "C0516UPPMT3",
    "channel_name": "aihub-feedback",
    "date_file": "2023-09-28.json",
    "message_count": 16,
    "start_time": "1695928833.994829",
    "end_time": "1695945071.389759",
    "is_thread": true
  }
}