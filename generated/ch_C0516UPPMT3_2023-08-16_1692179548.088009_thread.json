{
  "id": "ch_C0516UPPMT3_2023-08-16_1692179548.088009_thread",
  "type": "channel",
  "channel_name": "aihub-feedback",
  "conversation_type": "thread",
  "participants": [
    "Dale DeLoy",
    "Josh Heidebrecht",
    "Rafal",
    "Sławek Biel"
  ],
  "messages": [
    {
      "sender": "Rafal",
      "user_id": "U023S84DFDJ",
      "message": "Exactly, we have it in our backlog to create an agent tool that will handle such cases, but it’s not started yet\ncc @Sławek Biel",
      "time": "02:52",
      "timestamp": "1692179548.088009",
      "is_reply": false
    },
    {
      "sender": "Sławek Biel",
      "user_id": "U03E1LBTKV2",
      "message": "@Dale DeLoy If you are able to share sample documents and kind of prompts you want to run that would be useful",
      "time": "02:59",
      "timestamp": "1692179985.768689",
      "is_reply": true
    },
    {
      "sender": "Dale DeLoy",
      "user_id": "U01T2LEP1FF",
      "message": "Here are some of the expected prompts with the goal of creating a medical record summary",
      "time": "05:05",
      "timestamp": "1692187511.494869",
      "is_reply": true
    },
    {
      "sender": "Dale DeLoy",
      "user_id": "U01T2LEP1FF",
      "message": "Here is a sample redacted medical record",
      "time": "05:06",
      "timestamp": "1692187577.081129",
      "is_reply": true
    },
    {
      "sender": "Dale DeLoy",
      "user_id": "U01T2LEP1FF",
      "message": "It was compressed to fit under the 50mb file size limit",
      "time": "05:06",
      "timestamp": "1692187606.811239",
      "is_reply": true
    },
    {
      "sender": "Sławek Biel",
      "user_id": "U03E1LBTKV2",
      "message": "Thank you @Dale DeLoy",
      "time": "05:11",
      "timestamp": "1692187877.081389",
      "is_reply": true
    },
    {
      "sender": "Rafal",
      "user_id": "U023S84DFDJ",
      "message": "@Sławek Biel can you add it to long-doc benchmark once you have time?",
      "time": "05:12",
      "timestamp": "1692187978.199149",
      "is_reply": true
    },
    {
      "sender": "Josh Heidebrecht",
      "user_id": "U02CL5VQL3S",
      "message": "I’ve been hit by this as well. If I send just the subset of the doc that I care about it works great, but if I send the whole doc the same prompts fail.\n\nWhat I’ve envisioned is a solution builder approach of split classifying a large doc into sections—Most long docs have logical sections that should be easy to split on. Then in our prompts we specify which section of the doc we want to send the prompt to.\n\nIn the world of vector databases, I wonder if there are hints that could be provided and a UI to make this easier for customers.",
      "time": "10:33",
      "timestamp": "1692207180.865709",
      "is_reply": true
    },
    {
      "sender": "Dale DeLoy",
      "user_id": "U01T2LEP1FF",
      "message": "I look at this differently as the documents are already being chunked up to fit within the LLM limits so no split classification required.  The issue is relevance of the chunk and being able to receive responses for all chunks or those that fit relevance thresholds",
      "time": "12:55",
      "timestamp": "1692215703.227369",
      "is_reply": true
    }
  ],
  "metadata": {
    "channel_id": "C0516UPPMT3",
    "channel_name": "aihub-feedback",
    "date_file": "2023-08-16.json",
    "message_count": 9,
    "start_time": "1692179548.088009",
    "end_time": "1692215703.227369",
    "is_thread": true
  }
}