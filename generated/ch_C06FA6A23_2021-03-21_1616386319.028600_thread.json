{
  "id": "ch_C06FA6A23_2021-03-21_1616386319.028600_thread",
  "type": "channel",
  "channel_name": "discuss-engineering",
  "conversation_type": "thread",
  "participants": [
    "Ashish",
    "Anant",
    "sudeep"
  ],
  "messages": [
    {
      "sender": "sudeep",
      "user_id": "UCWRN72EP",
      "message": "checking, creating this thread for any info on this",
      "time": "21:11",
      "timestamp": "1616386319.028600",
      "is_reply": false
    },
    {
      "sender": "sudeep",
      "user_id": "UCWRN72EP",
      "message": "No backlog in rabbitmq, celery workers look okay",
      "time": "21:25",
      "timestamp": "1616387116.028900",
      "is_reply": true
    },
    {
      "sender": "sudeep",
      "user_id": "UCWRN72EP",
      "message": "nginx has been crashlooping. not sure if this is contributing to slowness\n```2021-03-22 09:48:47.910 IST\n2021/03/22 04:18:27 [emerg] 8#8: host not found in resolver \"kube-dns.kube-system.svc.cluster.local\" in /etc/nginx/nginx.conf:72\nError\n2021-03-22 09:48:47.910 IST\nnginx: [emerg] host not found in resolver \"kube-dns.kube-system.svc.cluster.local\" in /etc/nginx/nginx.conf:72```",
      "time": "21:26",
      "timestamp": "1616387164.029100",
      "is_reply": true
    },
    {
      "sender": "Anant",
      "user_id": "U0U100MNZ",
      "message": "I think it's status updates that is failing -- the flow is completing but the UI shows it's still working",
      "time": "22:00",
      "timestamp": "1616389253.029400",
      "is_reply": true
    },
    {
      "sender": "Anant",
      "user_id": "U0U100MNZ",
      "message": "",
      "time": "22:01",
      "timestamp": "1616389277.029600",
      "is_reply": true
    },
    {
      "sender": "Anant",
      "user_id": "U0U100MNZ",
      "message": "can we get it fixed please",
      "time": "22:01",
      "timestamp": "1616389296.030200",
      "is_reply": true
    },
    {
      "sender": "Anant",
      "user_id": "U0U100MNZ",
      "message": "it would be hard for us to do any demos if this is not fixed.",
      "time": "22:02",
      "timestamp": "1616389326.030400",
      "is_reply": true
    },
    {
      "sender": "Anant",
      "user_id": "U0U100MNZ",
      "message": "it's basically -- nginx randomly for some requests takes forever and then eventually returns error (even though flow is successfully completing)",
      "time": "22:06",
      "timestamp": "1616389617.030600",
      "is_reply": true
    },
    {
      "sender": "Anant",
      "user_id": "U0U100MNZ",
      "message": "does it have anything to do with changes we made for the marketing website? + @Ashish",
      "time": "22:08",
      "timestamp": "1616389732.031000",
      "is_reply": true
    },
    {
      "sender": "sudeep",
      "user_id": "UCWRN72EP",
      "message": "i have also removed the unhealthy nginx pod (although no traffic should have been going to it)",
      "time": "22:09",
      "timestamp": "1616389777.031200",
      "is_reply": true
    },
    {
      "sender": "Anant",
      "user_id": "U0U100MNZ",
      "message": "tried again -- same problem -- it got stuck",
      "time": "22:11",
      "timestamp": "1616389882.031400",
      "is_reply": true
    },
    {
      "sender": "Anant",
      "user_id": "U0U100MNZ",
      "message": "",
      "time": "22:11",
      "timestamp": "1616389894.031600",
      "is_reply": true
    },
    {
      "sender": "Anant",
      "user_id": "U0U100MNZ",
      "message": "eventually it will fail and the status will never update beyond this",
      "time": "22:12",
      "timestamp": "1616389922.032000",
      "is_reply": true
    },
    {
      "sender": "Anant",
      "user_id": "U0U100MNZ",
      "message": "(the flow will succeed though)",
      "time": "22:12",
      "timestamp": "1616389943.032200",
      "is_reply": true
    },
    {
      "sender": "Anant",
      "user_id": "U0U100MNZ",
      "message": "yep, eventually failed",
      "time": "22:13",
      "timestamp": "1616389984.032400",
      "is_reply": true
    },
    {
      "sender": "Anant",
      "user_id": "U0U100MNZ",
      "message": "",
      "time": "22:13",
      "timestamp": "1616389995.032600",
      "is_reply": true
    },
    {
      "sender": "sudeep",
      "user_id": "UCWRN72EP",
      "message": "can i get link to your flow ? i just ran one successfully",
      "time": "22:15",
      "timestamp": "1616390119.033600",
      "is_reply": true
    },
    {
      "sender": "Anant",
      "user_id": "U0U100MNZ",
      "message": "don't run flow -- run a binary: https://instabase.com/anantb/workspace/fs/Instabase%20Drive/depot/customer-work/westpac/workspace-anantb/build/bin/PAS/",
      "time": "22:16",
      "timestamp": "1616390179.033800",
      "is_reply": true
    },
    {
      "sender": "Anant",
      "user_id": "U0U100MNZ",
      "message": "input: https://instabase.com/anantb/workspace/fs/Instabase%20Drive/depot/customer-work/westpac/workspace-anantb/3c%20PAS/input/",
      "time": "22:16",
      "timestamp": "1616390201.034000",
      "is_reply": true
    },
    {
      "sender": "sudeep",
      "user_id": "UCWRN72EP",
      "message": "i was able to run your binary to completion very quickly @Anant",
      "time": "22:29",
      "timestamp": "1616390959.034200",
      "is_reply": true
    },
    {
      "sender": "Anant",
      "user_id": "U0U100MNZ",
      "message": "let me try again",
      "time": "22:29",
      "timestamp": "1616390986.034600",
      "is_reply": true
    },
    {
      "sender": "sudeep",
      "user_id": "UCWRN72EP",
      "message": "i used this folder for input : anantb/workspace/fs/Instabase Drive/depot/customer-work/westpac/workspace-anantb/3c PAS/input",
      "time": "22:31",
      "timestamp": "1616391079.034800",
      "is_reply": true
    },
    {
      "sender": "Anant",
      "user_id": "U0U100MNZ",
      "message": "yes",
      "time": "22:31",
      "timestamp": "1616391114.035000",
      "is_reply": true
    },
    {
      "sender": "Anant",
      "user_id": "U0U100MNZ",
      "message": "for me it hangs",
      "time": "22:32",
      "timestamp": "1616391121.035200",
      "is_reply": true
    },
    {
      "sender": "Anant",
      "user_id": "U0U100MNZ",
      "message": "it got hung again",
      "time": "22:32",
      "timestamp": "1616391125.035400",
      "is_reply": true
    },
    {
      "sender": "sudeep",
      "user_id": "UCWRN72EP",
      "message": "that's weird",
      "time": "22:32",
      "timestamp": "1616391145.035600",
      "is_reply": true
    },
    {
      "sender": "Anant",
      "user_id": "U0U100MNZ",
      "message": "as you can see below -- it's hung since last 1 min",
      "time": "22:32",
      "timestamp": "1616391167.035800",
      "is_reply": true
    },
    {
      "sender": "Anant",
      "user_id": "U0U100MNZ",
      "message": "I can consistently reproduce it -- every single time. :slightly_smiling_face:",
      "time": "22:38",
      "timestamp": "1616391496.036200",
      "is_reply": true
    },
    {
      "sender": "sudeep",
      "user_id": "UCWRN72EP",
      "message": "the problem is downstream of nginx. api-server-apps is not able to connect to accout-tservice",
      "time": "22:50",
      "timestamp": "1616392231.036700",
      "is_reply": true
    },
    {
      "sender": "sudeep",
      "user_id": "UCWRN72EP",
      "message": "```Traceback (most recent call last):\n  File \"/home/ibuser/.local/lib/python3.7/site-packages/thrift/transport/TSocket.py\", line 99, in open\n    addrs = self._resolveAddr()\n  File \"/home/ibuser/.local/lib/python3.7/site-packages/thrift/transport/TSocket.py\", line 42, in _resolveAddr\n    socket.AI_PASSIVE | socket.AI_ADDRCONFIG)\n  File \"/home/ibuser/.local/lib/python3.7/site-packages/gevent/_socketcommon.py\", line 212, in getaddrinfo\n    addrlist = get_hub().resolver.getaddrinfo(host, port, family, type, proto, flags)\n  File \"/home/ibuser/.local/lib/python3.7/site-packages/gevent/resolver/thread.py\", line 65, in getaddrinfo\n    return self.pool.apply(_socket.getaddrinfo, args, kwargs)\n  File \"/home/ibuser/.local/lib/python3.7/site-packages/gevent/pool.py\", line 159, in apply\n    return self.spawn(func, *args, **kwds).get()\n  File \"src/gevent/event.py\", line 268, in gevent._event.AsyncResult.get\n  File \"src/gevent/event.py\", line 296, in gevent._event.AsyncResult.get\n  File \"src/gevent/event.py\", line 286, in gevent._event.AsyncResult.get\n  File \"src/gevent/event.py\", line 266, in gevent._event.AsyncResult._raise_exception\n  File \"/home/ibuser/.local/lib/python3.7/site-packages/gevent/_compat.py\", line 47, in reraise\n    raise value.with_traceback(tb)\n  File \"/home/ibuser/.local/lib/python3.7/site-packages/gevent/threadpool.py\", line 281, in _worker\n    value = func(*args, **kwargs)\nsocket.gaierror: [Errno -3] Temporary failure in name resolution\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/instabase-api-server-apps/py/instabase/utils/rpc/pool.py\", line 66, in _create_thrift_client\n    transport.open()\n  File \"/home/ibuser/.local/lib/python3.7/site-packages/thrift/transport/TTransport.py\", line 155, in open\n    return self.__trans.open()\n  File \"/home/ibuser/.local/lib/python3.7/site-packages/thrift/transport/TSocket.py\", line 103, in open\n    raise TTransportException(type=TTransportException.NOT_OPEN, message=msg, inner=gai)\nthrift.transport.TTransport.TTransportException: failed to resolve sockaddr for service-account-tservice.instabase-prod.svc.cluster.local:5050```",
      "time": "22:50",
      "timestamp": "1616392234.036900",
      "is_reply": true
    },
    {
      "sender": "sudeep",
      "user_id": "UCWRN72EP",
      "message": "l;ooking further, this explains 40x on your calls to /api/v1/jobs/status.. endpoint",
      "time": "22:50",
      "timestamp": "1616392244.037100",
      "is_reply": true
    },
    {
      "sender": "sudeep",
      "user_id": "UCWRN72EP",
      "message": "also nginx pod crashloop was also because of not being able to reach DNS. looking in that direction for now",
      "time": "22:56",
      "timestamp": "1616392569.037500",
      "is_reply": true
    },
    {
      "sender": "Ashish",
      "user_id": "U3UJ09DJ6",
      "message": "it could be a kubernetes level matter\n\nthe new cluster is on k8s 1.18 and the old is on 1.16",
      "time": "23:07",
      "timestamp": "1616393257.037800",
      "is_reply": true
    },
    {
      "sender": "sudeep",
      "user_id": "UCWRN72EP",
      "message": "just confirmed - all DNS errors from api-server-apps to acct service are in 1 pod only \"deployment-api-server-apps-5884dc6d8c-rqng9\"",
      "time": "23:08",
      "timestamp": "1616393311.038000",
      "is_reply": true
    },
    {
      "sender": "sudeep",
      "user_id": "UCWRN72EP",
      "message": "this explains why the error may not be consistent when Anant and I tried flows and it worked for me but not him",
      "time": "23:09",
      "timestamp": "1616393348.038200",
      "is_reply": true
    },
    {
      "sender": "sudeep",
      "user_id": "UCWRN72EP",
      "message": "i can remove this unhealthy pod, but we need to rc the issue and affected pods, the issue could be affecting other pods too",
      "time": "23:09",
      "timestamp": "1616393381.038400",
      "is_reply": true
    },
    {
      "sender": "Ashish",
      "user_id": "U3UJ09DJ6",
      "message": "@Anant if access to the old cluster will help you, I can set that up for you",
      "time": "23:12",
      "timestamp": "1616393543.038700",
      "is_reply": true
    },
    {
      "sender": "sudeep",
      "user_id": "UCWRN72EP",
      "message": "```Sudeeps-MacBook-Pro-2:file-tservice sudeep$ kubectl -n instabase-prod logs deployment-api-server-apps-5884dc6d8c-rqng9 -c api-server-apps | grep -i \"name resolution\" | wc -l\n     540```",
      "time": "23:12",
      "timestamp": "1616393575.038900",
      "is_reply": true
    },
    {
      "sender": "sudeep",
      "user_id": "UCWRN72EP",
      "message": "other pods have counts 0 @Ashish, i think the problem is not related to your change",
      "time": "23:13",
      "timestamp": "1616393600.039100",
      "is_reply": true
    },
    {
      "sender": "Ashish",
      "user_id": "U3UJ09DJ6",
      "message": "0 counts of ?",
      "time": "23:13",
      "timestamp": "1616393623.039400",
      "is_reply": true
    },
    {
      "sender": "sudeep",
      "user_id": "UCWRN72EP",
      "message": "0 counts of DNS failure in resolving acct-service",
      "time": "23:14",
      "timestamp": "1616393652.039600",
      "is_reply": true
    },
    {
      "sender": "sudeep",
      "user_id": "UCWRN72EP",
      "message": "https://instabase.slack.com/archives/C06FA6A23/p1616392234036900?thread_ts=1616386319.028600&cid=C06FA6A23",
      "time": "23:14",
      "timestamp": "1616393660.039800",
      "is_reply": true
    },
    {
      "sender": "Ashish",
      "user_id": "U3UJ09DJ6",
      "message": "I see",
      "time": "23:14",
      "timestamp": "1616393669.040100",
      "is_reply": true
    },
    {
      "sender": "sudeep",
      "user_id": "UCWRN72EP",
      "message": "this is the error that we see in this pod",
      "time": "23:14",
      "timestamp": "1616393679.040300",
      "is_reply": true
    },
    {
      "sender": "Ashish",
      "user_id": "U3UJ09DJ6",
      "message": "let's also check for all the pods; I am checking gcloud logs",
      "time": "23:14",
      "timestamp": "1616393699.040500",
      "is_reply": true
    },
    {
      "sender": "Anant",
      "user_id": "U0U100MNZ",
      "message": "I’ll work on my stuff tomorrow morning onward",
      "time": "23:15",
      "timestamp": "1616393723.041300",
      "is_reply": true
    },
    {
      "sender": "sudeep",
      "user_id": "UCWRN72EP",
      "message": "yeah @Ashish i checked all of the other api-serer-apps pods, but not sure how to check across all deployments",
      "time": "23:15",
      "timestamp": "1616393724.041500",
      "is_reply": true
    },
    {
      "sender": "Anant",
      "user_id": "U0U100MNZ",
      "message": "As long as it works tomorrow, I’m fine",
      "time": "23:15",
      "timestamp": "1616393739.042200",
      "is_reply": true
    },
    {
      "sender": "sudeep",
      "user_id": "UCWRN72EP",
      "message": "@Anant - can you try now once before you head off ?",
      "time": "23:16",
      "timestamp": "1616393767.042500",
      "is_reply": true
    },
    {
      "sender": "sudeep",
      "user_id": "UCWRN72EP",
      "message": "@Ashish - i had also seen this DNS error in ojne of the nginx pods earlier btw\nhttps://instabase.slack.com/archives/C06FA6A23/p1616387164029100?thread_ts=1616386319.028600&cid=C06FA6A23",
      "time": "23:20",
      "timestamp": "1616394058.042700",
      "is_reply": true
    },
    {
      "sender": "Ashish",
      "user_id": "U3UJ09DJ6",
      "message": "line 72 is `resolver kube-dns.kube-system.svc.cluster.local valid=30s;`",
      "time": "23:23",
      "timestamp": "1616394197.043000",
      "is_reply": true
    },
    {
      "sender": "Ashish",
      "user_id": "U3UJ09DJ6",
      "message": "nginx couldn't resolve kube-dns",
      "time": "23:23",
      "timestamp": "1616394204.043200",
      "is_reply": true
    },
    {
      "sender": "sudeep",
      "user_id": "UCWRN72EP",
      "message": "yep",
      "time": "23:24",
      "timestamp": "1616394245.043500",
      "is_reply": true
    },
    {
      "sender": "Ashish",
      "user_id": "U3UJ09DJ6",
      "message": "i'll check nginx",
      "time": "23:25",
      "timestamp": "1616394315.043700",
      "is_reply": true
    },
    {
      "sender": "Ashish",
      "user_id": "U3UJ09DJ6",
      "message": "thrift errors can be seen here: https://console.cloud.google.com/logs/query;query=resource.type%3D%22k8s_container%22%0Ar[…]ame%20resolution%22;timeRange=P7D?project=instabase-main (https://console.cloud.google.com/logs/query;query=resource.type%3D%22k8s_container%22%0Aresource.labels.cluster_name%3D%22instabase-main-prod-001%22%0A%22Temporary%20failure%20in%20name%20resolution%22;timeRange=P7D?project=instabase-main)",
      "time": "23:25",
      "timestamp": "1616394328.043900",
      "is_reply": true
    },
    {
      "sender": "Ashish",
      "user_id": "U3UJ09DJ6",
      "message": "",
      "time": "23:25",
      "timestamp": "1616394347.044200",
      "is_reply": true
    },
    {
      "sender": "sudeep",
      "user_id": "UCWRN72EP",
      "message": "other services reporting name resolution failures -\nhttps://console.cloud.google.com/logs/query;query=resource.type%3D%22k8s_container%22%0Ar[…]0resolution%22%2529;timeRange=P7D?project=instabase-main (https://console.cloud.google.com/logs/query;query=resource.type%3D%22k8s_container%22%0Aresource.labels.cluster_name%3D%22instabase-main-prod-001%22%0A-resource.labels.pod_name%3D%22deployment-api-server-apps-5884dc6d8c-rqng9%22%0AtextPayload:%2528%22Temporary%20failure%20in%20name%20resolution%22%2529;timeRange=P7D?project=instabase-main)",
      "time": "23:30",
      "timestamp": "1616394643.044600",
      "is_reply": true
    },
    {
      "sender": "sudeep",
      "user_id": "UCWRN72EP",
      "message": "started around this time",
      "time": "23:32",
      "timestamp": "1616394742.044900",
      "is_reply": true
    }
  ],
  "metadata": {
    "channel_id": "C06FA6A23",
    "channel_name": "discuss-engineering",
    "date_file": "2021-03-21.json",
    "message_count": 58,
    "start_time": "1616386319.028600",
    "end_time": "1616394742.044900",
    "is_thread": true
  }
}