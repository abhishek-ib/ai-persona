{
  "id": "ch_C0516UPPMT3_2023-10-26_1698312308.233009_thread",
  "type": "channel",
  "channel_name": "aihub-feedback",
  "conversation_type": "thread",
  "participants": [
    "Sławek Biel",
    "lydia",
    "Lee"
  ],
  "messages": [
    {
      "sender": "Lee",
      "user_id": "U01J31371LZ",
      "message": "Hi, I much prefer this design, and it makes a lot more sense what we are trying to achieve with the two different options, however in practice this isn’t the main difference between the two types of prompts.\n\nVery often in anything other than the most simple extractions you need a ‘complex prompt’ to be able to extract data, as you need to provide more context and guardrails to get the data you need. For this reason calling the option reasoning isn’t very accurate to the most common use for complex prompt.\n\nExample uses for ‘complex prompt’ that aren’t just about reasoning:\n• Extracting 5 data points and returning a JSON object.\n• Extracting a single data point where you need to provide more context\n• Extracting a paragraph of text - for example a clause in a contract. \n• Creating a table where you specify the columns. \nI think the current description where it says ‘not explicitly extracting’ is the misleading part.",
      "time": "02:25",
      "timestamp": "1698312308.233009",
      "is_reply": false
    },
    {
      "sender": "Lee",
      "user_id": "U01J31371LZ",
      "message": "@Bastiane",
      "time": "02:32",
      "timestamp": "1698312742.948609",
      "is_reply": true
    },
    {
      "sender": "lydia",
      "user_id": "UJK4LKYSJ",
      "message": "Thanks Lee for the feedback. I think we will need to follow-up on this some more and see examples before making a decision. I don't want to rush into any changes.\n\nI think what is perhaps happening is that, \"extraction\" mode does special things that work well for the extraction examples we've seen, but it doesn't work well for a lot of complex examples that _you_ see. \"reasoning\" mode (as we've implemented it) is a much less opinionated wrapper around LLMs, so it allows you to prompt engineer directly with the OpenAI model. This works well for advanced users, but doesn't well for less advanced users (e.g. they wouldn't know the exact prompt to write to get the answer they're looking for).\n\nI would say, the intention of the product is what we describe in the \"Extraction\" and \"Reasoning\" descriptions. However, there's some % of advanced use cases that neither really cover, and those use cases are better supported by advanced users using the Reasoning mode to essentially write whatever prompt they want to the model.",
      "time": "08:30",
      "timestamp": "1698334208.773319",
      "is_reply": true
    },
    {
      "sender": "Sławek Biel",
      "user_id": "U03E1LBTKV2",
      "message": "As a related note it would be nice to get some data on the usage patterns.\n\nFrom the model dev point of view we hoped that majority of the usecases can be solved with basic/extraction prompts. Here the ibllm has control over prompting which gives use more options. We can make it more efficient/cheaper. And it makes many things simpler to handle (provenance, confidences, parsings, lists) also metrics and benchmarks.\n\nBut if it turns out more often than not it’s not sufficient than we’d need to rethink how we approach this.",
      "time": "12:11",
      "timestamp": "1698347482.842719",
      "is_reply": true
    }
  ],
  "metadata": {
    "channel_id": "C0516UPPMT3",
    "channel_name": "aihub-feedback",
    "date_file": "2023-10-26.json",
    "message_count": 4,
    "start_time": "1698312308.233009",
    "end_time": "1698347482.842719",
    "is_thread": true
  }
}