{
  "id": "ch_C0516UPPMT3_2024-12-12_1734023093.104639_thread",
  "type": "channel",
  "channel_name": "aihub-feedback",
  "conversation_type": "thread",
  "participants": [
    "jack.robbins",
    "Hamish",
    "Jasper",
    "Kaustubh (KD)",
    "Sanch",
    "Serena"
  ],
  "messages": [
    {
      "sender": "Hamish",
      "user_id": "U06G3LGDBQU",
      "message": "Hey, sharing the upload duplication feedback I saw from Deloitte AU/ANZ.\n\n*Fraud Detection - Insurance Claims Processing, Mortgage Origination*\n• \"Can AI Hub detect if the same file has been uploaded before?\"\n• \"If someone makes a claim yesterday, we should flag another claim today - can you do that?\"\n    ◦ Unsure if this would be the same document, or the same extracted data e.g. account number/name\nI imagine there are a lot of potential edge cases we would need to be careful of where duplicate uploads are expected.\n\n*Accidental Duplication - Superannuation Advice Monitoring* \n• \"Sometimes two operators pick up the same case from the unassigned pool and start working on it. If this case was pushed through IB twice, can we detect this and flag it?\"\nThis seems like a more obvious product improvement. Could have cost savings on our side even if we just pulled past results. Do we want to own this kind of functionality or should this be the clients responsibility to manage duplication?",
      "time": "09:04",
      "timestamp": "1734023093.104639",
      "is_reply": false
    },
    {
      "sender": "Serena",
      "user_id": "U01CZ3LBFU4",
      "message": "@Hamish are you asking about detecting duplicates in just app runs / deployment runs? or are you also asking about detecting duplicates in Build?\n\ncc @Kaustubh (KD) @jack.robbins",
      "time": "09:45",
      "timestamp": "1734025507.316859",
      "is_reply": true
    },
    {
      "sender": "Hamish",
      "user_id": "U06G3LGDBQU",
      "message": "Just in app runs (but I could imagine Build being a useful nice to have)",
      "time": "09:59",
      "timestamp": "1734026360.198379",
      "is_reply": true
    },
    {
      "sender": "Kaustubh (KD)",
      "user_id": "U06G3LGPDFW",
      "message": "There are certainly cases where users prefer not to deduplicate, but this sounds like a new feature request cc: @jack.robbins",
      "time": "11:20",
      "timestamp": "1734031200.798709",
      "is_reply": true
    },
    {
      "sender": "Sanch",
      "user_id": "U04UB9F2AKZ",
      "message": "this was also requested by Kering (accidental duplication)",
      "time": "11:21",
      "timestamp": "1734031309.538179",
      "is_reply": true
    },
    {
      "sender": "Jasper",
      "user_id": "U02KPTJGSCC",
      "message": "For the simpler non-fraud duplicate detection we have an advanced app that we may be able to publish on AI Hub. For all other cases there are several approaches may be useful:\n\n• Validations\n• Fraud Detection using Resistant AI\n• Case Collation V2 where we may have an ID that can collect cases per customer\n• Check Sum / Hash calculation - either custom or by re-using the mentioned advanced app\nIn other words, we need more use case discovery here. I agree it's a common request in any case.",
      "time": "13:55",
      "timestamp": "1734040538.656159",
      "is_reply": true
    },
    {
      "sender": "jack.robbins",
      "user_id": "U07AZ2E1BRS",
      "message": "Was going to suggest some sort of workaround if each file/case has a field with a unique ID, you could use a validation or UDF to lookup if it's already been processed. This would only work in simple cases & it seems we've handled similar situations in IB platform.",
      "time": "14:00",
      "timestamp": "1734040805.106379",
      "is_reply": true
    },
    {
      "sender": "jack.robbins",
      "user_id": "U07AZ2E1BRS",
      "message": "Surprisingly not seeing an existing PFR for it",
      "time": "14:00",
      "timestamp": "1734040849.870069",
      "is_reply": true
    }
  ],
  "metadata": {
    "channel_id": "C0516UPPMT3",
    "channel_name": "aihub-feedback",
    "date_file": "2024-12-12.json",
    "message_count": 8,
    "start_time": "1734023093.104639",
    "end_time": "1734040849.870069",
    "is_thread": true
  }
}