{
  "id": "ch_C0976HB6ZPT_2025-09-11_1757629096.896679_thread",
  "type": "channel",
  "channel_name": "proj-agent-mode",
  "conversation_type": "thread",
  "participants": [
    "jordy.vlan",
    "Anil"
  ],
  "messages": [
    {
      "sender": "Anil",
      "user_id": "U01BH8XBR55",
      "message": "The Gemini API has a limit to the size of the structured output schema. We can extract ~ 25 fields at a time in one call.\nIf we have > 25 fields to extract, we batch into groups of 25 and send the input document each time to extract the fields. There is implicit caching but that is not being hit. This can get expensive quickly.\n\nI got a bunch of good pointers from Google reps on how to optimize this\nWhen we send request to Gemini, the final input to model is system prompt + schema + user prompt.\nuser_prompt includes the document.\nFor caching to work, everything from the top has to be cached. If schema changes, then cache will no longer be hit.\nWorkarounds:\n1. Pass schema as text and ask it to return JSON. This way, we donâ€™t have 25 field limit. On Berkley function calling benchmark, apparently text does better than structured output for function calling with pro. \n2. Use turns. Ask it to return 25, then next 25 and so on as turns instead of new conversations. \n3. Use explicit caching. They have custom TTL. \nOptimizations to do later.",
      "time": "15:18",
      "timestamp": "1757629096.896679",
      "is_reply": false
    },
    {
      "sender": "jordy.vlan",
      "user_id": "U072CDMB4N8",
      "message": "Also true for Vertex?\nThis seems extremely strange that they would limit this",
      "time": "23:42",
      "timestamp": "1757659327.822529",
      "is_reply": true
    },
    {
      "sender": "jordy.vlan",
      "user_id": "U072CDMB4N8",
      "message": "Another hack = no user prompt change and attach schema later as JSON blob in a \"model\" message (as if it were generated by the model). Then at least you would cache most of it",
      "time": "23:44",
      "timestamp": "1757659492.679779",
      "is_reply": true
    },
    {
      "sender": "jordy.vlan",
      "user_id": "U072CDMB4N8",
      "message": "Also for Build, any change to a field should mean that you place the field at the end of the schema to still maximally exploit the caching mechanism. (Exceptions being inside derived fields)",
      "time": "23:45",
      "timestamp": "1757659557.321639",
      "is_reply": true
    }
  ],
  "metadata": {
    "channel_id": "C0976HB6ZPT",
    "channel_name": "proj-agent-mode",
    "date_file": "2025-09-11.json",
    "message_count": 4,
    "start_time": "1757629096.896679",
    "end_time": "1757659557.321639",
    "is_thread": true
  }
}