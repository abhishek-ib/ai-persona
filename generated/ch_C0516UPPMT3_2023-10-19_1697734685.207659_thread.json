{
  "id": "ch_C0516UPPMT3_2023-10-19_1697734685.207659_thread",
  "type": "channel",
  "channel_name": "aihub-feedback",
  "conversation_type": "thread",
  "participants": [
    "Bastiane",
    "Kerry",
    "Nikolaos Kofinas",
    "Will McDermott"
  ],
  "messages": [
    {
      "sender": "Will McDermott",
      "user_id": "U03DJMXCNCF",
      "message": "Separate challenge on the same documents as above; using prompt \"extract all line items, with units, price, and extension price as a JSON array\". The output when running app for doc 1 includes \"extension_price\" as the last variable, the output for doc 2 includes \"billing_price\" as the last variable instead of \"extension_price\"",
      "time": "09:58",
      "timestamp": "1697734685.207659",
      "is_reply": false
    },
    {
      "sender": "Kerry",
      "user_id": "UCX3VGDJR",
      "message": "can you clarify if this is 1) inaccurate results on some files, or 2) there's a difference between the result in Build and App? (as in, in Build we get the right data; in App we couldn't, or another way around)",
      "time": "10:32",
      "timestamp": "1697736742.113019",
      "is_reply": true
    },
    {
      "sender": "Will McDermott",
      "user_id": "U03DJMXCNCF",
      "message": "@Kerry yeah sorry this original example is through Apps. I just checked all the docs in Build and the variables are also inconsistent there. So 1) inaccurate results across both Build and Apps\n\nIt also returns a table in 1 of the 3 examples which is unneeded, but wonder if that's a product of my prompt not being refined enough",
      "time": "10:45",
      "timestamp": "1697737559.867629",
      "is_reply": true
    },
    {
      "sender": "Will McDermott",
      "user_id": "U03DJMXCNCF",
      "message": "",
      "time": "10:46",
      "timestamp": "1697737610.118369",
      "is_reply": true
    },
    {
      "sender": "Kerry",
      "user_id": "UCX3VGDJR",
      "message": "Cool, we'll improve the accuracy here -- cc @Nikolaos Kofinas @lydia here are some good sample data to add to the benchmark :slightly_smiling_face: all these files look similar, interested to know why extraction is successful in some cases whereas not in some other files",
      "time": "11:06",
      "timestamp": "1697738786.486169",
      "is_reply": true
    },
    {
      "sender": "Will McDermott",
      "user_id": "U03DJMXCNCF",
      "message": "thank you guys!",
      "time": "11:22",
      "timestamp": "1697739725.212099",
      "is_reply": true
    },
    {
      "sender": "Nikolaos Kofinas",
      "user_id": "U03DWCUEBHT",
      "message": "this is a complex prompt and the model is not grounded to labels. With a bit of refinement of the prompt (e.g. state the json format of the output like we do for non-complex prompts) this should be fixed. Randomness is expected from the GPT models and we must write prompts to leave as few options to the model as possible",
      "time": "11:23",
      "timestamp": "1697739833.343109",
      "is_reply": true
    },
    {
      "sender": "Nikolaos Kofinas",
      "user_id": "U03DWCUEBHT",
      "message": "here is a good grounding prompt that works really well (our extraction prompt): https://github.com/instabase/instabase/blob/master/shared-utils/py-utils/ibllm/src/py/instabase/ibllm/code_labs/prompt_templates/extraction.py#L201\n(Side note: Sometimes being nice to the model e.g. starting with “Please” helps  :stuck_out_tongue: )",
      "time": "11:26",
      "timestamp": "1697739967.057709",
      "is_reply": true
    },
    {
      "sender": "Bastiane",
      "user_id": "U046R81BMM4",
      "message": "This is super helpful. Thank you @Nikolaos Kofinas . It’s worth discussing how we can enable users to do this more easily in the product and/or provide more guidance in documentation cc @lydia @melissa.amos",
      "time": "12:31",
      "timestamp": "1697743916.876469",
      "is_reply": true
    }
  ],
  "metadata": {
    "channel_id": "C0516UPPMT3",
    "channel_name": "aihub-feedback",
    "date_file": "2023-10-19.json",
    "message_count": 9,
    "start_time": "1697734685.207659",
    "end_time": "1697743916.876469",
    "is_thread": true
  }
}