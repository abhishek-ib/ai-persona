{
  "id": "ch_C0516UPPMT3_2024-01-29_1706546760.035729_thread",
  "type": "channel",
  "channel_name": "aihub-feedback",
  "conversation_type": "thread",
  "participants": [
    "Serena",
    "lydia"
  ],
  "messages": [
    {
      "sender": "Serena",
      "user_id": "U01CZ3LBFU4",
      "message": "ah maybe my previous explanation wasn’t clear enough?\n• default selection of field with output X\n    ◦ this used the doc digitized without FR, with “Single Field” as the data type\n• change to table and object detection to generate output Y\n    ◦ this used the doc digitized with FR, *with “Single Field” as the data type* (see my previous message  (https://instabase.slack.com/archives/C0516UPPMT3/p1706291656888029?thread_ts=1706142701.275749&cid=C0516UPPMT3)for detailed explanation)\n    ◦ note that the top of the frontend still says “Single field” next to output Y\n    ◦ you would need to click “Run all” to run with “Table” as the data type\n• change back to selection of field - output remains Y even though on top it says Single Field again\n    ◦ to the frontend, nothing has changed since you last ran the field to get output Y",
      "time": "08:46",
      "timestamp": "1706546760.035729",
      "is_reply": false
    },
    {
      "sender": "Serena",
      "user_id": "U01CZ3LBFU4",
      "message": "> hmm maybe im missing something. at 1:33 Bas turns on object recognition, and then runs the prompt ‘extract all text’ set as a Table field, and we get back the TDF table. this is working as per my expectation, not sure if im misunderstanding\n@Vishnu the misunderstanding is that for output Y, “Single Field” was used as the data type, so Lydia is asking whether we expect output Y (shown at 1:33 and 2:12) when “Single Field” is the data type\n\nsee above for why the FE passes “Single Field” to the backend to run the field, not “Table”",
      "time": "08:49",
      "timestamp": "1706546997.854689",
      "is_reply": true
    },
    {
      "sender": "lydia",
      "user_id": "UJK4LKYSJ",
      "message": "Just to close the loop here, I think the UX confusion is clear (fields are re-run with the saved version after re-digitization, not what the user currently sees) and captured in https://instabase.atlassian.net/browse/INSIGHTS-6028.\n\nOn my question of if extraction results should be different with object detection on or off, after talking with the Reader team, the answer is that it should be different, since if object detection is on, we send the Form Recognizer-enhanced version of the document text to the LLM.\n\nHowever, I have been seeing a lot of differences in extraction results between 23.49 and 24.02, where the above ^ doesn't seem to be true. I separately have another ticket (https://instabase.atlassian.net/browse/INSIGHTS-6032) for tracking that issue.",
      "time": "12:41",
      "timestamp": "1706560912.743919",
      "is_reply": true
    }
  ],
  "metadata": {
    "channel_id": "C0516UPPMT3",
    "channel_name": "aihub-feedback",
    "date_file": "2024-01-29.json",
    "message_count": 3,
    "start_time": "1706546760.035729",
    "end_time": "1706560912.743919",
    "is_thread": true
  }
}