{
  "id": "ch_C0516UPPMT3_2025-01-17_1737101097.694279_thread",
  "type": "channel",
  "channel_name": "aihub-feedback",
  "conversation_type": "thread",
  "participants": [
    "Jasper",
    "Kaustubh (KD)",
    "Hamish"
  ],
  "messages": [
    {
      "sender": "Jasper",
      "user_id": "U02KPTJGSCC",
      "message": "This is often requested during extraction as well. Related ticket (https://instabase.atlassian.net/browse/EPD-3189) but not exactly fuzzy matching.",
      "time": "00:04",
      "timestamp": "1737101097.694279",
      "is_reply": false
    },
    {
      "sender": "Kaustubh (KD)",
      "user_id": "U06G3LGPDFW",
      "message": "@Hamish are you using validation prompts? I think here since we generate code, we aren't really using the LLMs to validate but really just using LLMs to generate code that validates.\n\ncc: @andy + @lydia. I think this is worth investigating the user story here. Will follow up with you folks to understand what is possible",
      "time": "09:31",
      "timestamp": "1737135110.774539",
      "is_reply": true
    },
    {
      "sender": "Hamish",
      "user_id": "U06G3LGDBQU",
      "message": "Correct, I’m referring the the ability to use the LLM to do the validation itself (rather than generating deterministic code).\n\nThis would be a new feature that doesn’t currently exist",
      "time": "19:17",
      "timestamp": "1737170264.284189",
      "is_reply": true
    }
  ],
  "metadata": {
    "channel_id": "C0516UPPMT3",
    "channel_name": "aihub-feedback",
    "date_file": "2025-01-17.json",
    "message_count": 3,
    "start_time": "1737101097.694279",
    "end_time": "1737170264.284189",
    "is_thread": true
  }
}