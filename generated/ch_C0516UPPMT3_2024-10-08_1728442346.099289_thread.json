{
  "id": "ch_C0516UPPMT3_2024-10-08_1728442346.099289_thread",
  "type": "channel",
  "channel_name": "aihub-feedback",
  "conversation_type": "thread",
  "participants": [
    "Hamish"
  ],
  "messages": [
    {
      "sender": "Hamish",
      "user_id": "U06G3LGDBQU",
      "message": "Hey, for the new feature \"Selection based prompt optimisation\" my immediate thought is that the generated prompt is likely to overfit to the document we use to create the prompt (I haven't tested this, just a hunch). Have we considered allowing the user to 'annotate' multiple samples (this process could also create their golden set for testing simultaneously), and then allow the model to find commonalities between the docs and therefore generate a more generalisable prompt?\n\ncc @Kaustubh (KD)",
      "time": "19:52",
      "timestamp": "1728442346.099289",
      "is_reply": false
    }
  ],
  "metadata": {
    "channel_id": "C0516UPPMT3",
    "channel_name": "aihub-feedback",
    "date_file": "2024-10-08.json",
    "message_count": 1,
    "start_time": "1728442346.099289",
    "end_time": "1728442346.099289",
    "is_thread": true
  }
}