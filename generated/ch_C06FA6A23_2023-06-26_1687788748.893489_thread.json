{
  "id": "ch_C06FA6A23_2023-06-26_1687788748.893489_thread",
  "type": "channel",
  "channel_name": "discuss-engineering",
  "conversation_type": "thread",
  "participants": [
    "joshbronko",
    "vineeth",
    "Serena"
  ],
  "messages": [
    {
      "sender": "joshbronko",
      "user_id": "U031T0PNLUS",
      "message": "Are we using this anywhere in our development process? Would be slick for OpenAI Testing\nhttps://requests-cache.readthedocs.io/en/latest/index.html",
      "time": "07:12",
      "timestamp": "1687788748.893489",
      "is_reply": false
    },
    {
      "sender": "Serena",
      "user_id": "U01CZ3LBFU4",
      "message": "i canâ€™t find any usage of this in our codebase",
      "time": "09:30",
      "timestamp": "1687797019.447519",
      "is_reply": true
    },
    {
      "sender": "joshbronko",
      "user_id": "U031T0PNLUS",
      "message": "I am going to start to test with it on some of our calls with openai to not have to call subsequent calls",
      "time": "09:30",
      "timestamp": "1687797055.014669",
      "is_reply": true
    },
    {
      "sender": "vineeth",
      "user_id": "U0175SZ13F0",
      "message": "A better alternative would be semantic caching : https://github.com/zilliztech/GPTCache",
      "time": "23:40",
      "timestamp": "1687848022.688969",
      "is_reply": true
    }
  ],
  "metadata": {
    "channel_id": "C06FA6A23",
    "channel_name": "discuss-engineering",
    "date_file": "2023-06-26.json",
    "message_count": 4,
    "start_time": "1687788748.893489",
    "end_time": "1687848022.688969",
    "is_thread": true
  }
}