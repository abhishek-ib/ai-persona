{
  "id": "ch_C0516UPPMT3_2023-07-10_1688993927.594369_thread",
  "type": "channel",
  "channel_name": "aihub-feedback",
  "conversation_type": "thread",
  "participants": [
    "joshbronko",
    "Nikolaos Kofinas",
    "Rafal"
  ],
  "messages": [
    {
      "sender": "joshbronko",
      "user_id": "U031T0PNLUS",
      "message": "Any thoughts on above team? @Rafal @Varun Jain",
      "time": "05:58",
      "timestamp": "1688993927.594369",
      "is_reply": false
    },
    {
      "sender": "Rafal",
      "user_id": "U023S84DFDJ",
      "message": "Hey, we have a task in our backlog for it - we didn’t yet start on that\nWe were planning to ask the model to assess the confidence of the generated answer and then also evaluate the performance of such output on the ECE metric",
      "time": "06:01",
      "timestamp": "1688994076.005989",
      "is_reply": true
    },
    {
      "sender": "Rafal",
      "user_id": "U023S84DFDJ",
      "message": "@Varun Jain in the meanwhile, can we maybe ask OpenAI if they are planning at all to add the `logprobs` output in their Chat models?\nthey had it for `davinci` but for both `gpt-3.5-turbo` and `gpt-4` it’s not available :confused:",
      "time": "06:03",
      "timestamp": "1688994185.893919",
      "is_reply": true
    },
    {
      "sender": "Rafal",
      "user_id": "U023S84DFDJ",
      "message": "cc @Nikolaos Kofinas",
      "time": "06:03",
      "timestamp": "1688994191.437279",
      "is_reply": true
    },
    {
      "sender": "Nikolaos Kofinas",
      "user_id": "U03DWCUEBHT",
      "message": "for split class worked quit well (far from perfect though)",
      "time": "06:06",
      "timestamp": "1688994372.257919",
      "is_reply": true
    }
  ],
  "metadata": {
    "channel_id": "C0516UPPMT3",
    "channel_name": "aihub-feedback",
    "date_file": "2023-07-10.json",
    "message_count": 5,
    "start_time": "1688993927.594369",
    "end_time": "1688994372.257919",
    "is_thread": true
  }
}