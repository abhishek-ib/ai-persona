{
  "id": "ch_C0516UPPMT3_2023-05-09_1683643278.181429_thread",
  "type": "channel",
  "channel_name": "aihub-feedback",
  "conversation_type": "thread",
  "participants": [
    "vineeth",
    "joshbronko",
    "Matt Weaver",
    "Varun Jain",
    "Rafal"
  ],
  "messages": [
    {
      "sender": "joshbronko",
      "user_id": "U031T0PNLUS",
      "message": "With using AI-hub can we reenable the following type of prompt. Its super powerful and still only works on ai labs",
      "time": "07:41",
      "timestamp": "1683643278.181429",
      "is_reply": false
    },
    {
      "sender": "Matt Weaver",
      "user_id": "U01B8GFNUAC",
      "message": "Try \"Extract\" rather than return",
      "time": "07:41",
      "timestamp": "1683643297.257669",
      "is_reply": true
    },
    {
      "sender": "Matt Weaver",
      "user_id": "U01B8GFNUAC",
      "message": "I found that *Return JSON* and *Summarise as JSON* stopped working. Maybe because of some of the routing we're now doing on the back-end to handle long docs",
      "time": "07:41",
      "timestamp": "1683643319.395789",
      "is_reply": true
    },
    {
      "sender": "joshbronko",
      "user_id": "U031T0PNLUS",
      "message": "",
      "time": "07:42",
      "timestamp": "1683643348.648049",
      "is_reply": true
    },
    {
      "sender": "joshbronko",
      "user_id": "U031T0PNLUS",
      "message": "negative.",
      "time": "07:42",
      "timestamp": "1683643360.960489",
      "is_reply": true
    },
    {
      "sender": "Matt Weaver",
      "user_id": "U01B8GFNUAC",
      "message": "",
      "time": "07:43",
      "timestamp": "1683643412.118069",
      "is_reply": true
    },
    {
      "sender": "Matt Weaver",
      "user_id": "U01B8GFNUAC",
      "message": "this was working for me today. But i agree this kinda unreliable handling of prompts that request JSON output is a bad user experience.",
      "time": "07:44",
      "timestamp": "1683643452.294299",
      "is_reply": true
    },
    {
      "sender": "joshbronko",
      "user_id": "U031T0PNLUS",
      "message": "Would just be good to understand what is causing this to break",
      "time": "07:44",
      "timestamp": "1683643472.711669",
      "is_reply": true
    },
    {
      "sender": "Varun Jain",
      "user_id": "U019KDMQL14",
      "message": "@Hari @vineeth can we please look into this inconsistent behavior?",
      "time": "08:48",
      "timestamp": "1683647322.342249",
      "is_reply": true
    },
    {
      "sender": "vineeth",
      "user_id": "U0175SZ13F0",
      "message": "That’s the models behavior you can observe that even on chatgpt online",
      "time": "08:49",
      "timestamp": "1683647346.890979",
      "is_reply": true
    },
    {
      "sender": "vineeth",
      "user_id": "U0175SZ13F0",
      "message": "Do you see the same behaviour with `gpt-4` ?",
      "time": "08:49",
      "timestamp": "1683647363.281729",
      "is_reply": true
    },
    {
      "sender": "vineeth",
      "user_id": "U0175SZ13F0",
      "message": "It was not happening on legacy `ailabs` app since it was davinci model",
      "time": "08:49",
      "timestamp": "1683647399.305199",
      "is_reply": true
    },
    {
      "sender": "vineeth",
      "user_id": "U0175SZ13F0",
      "message": "But `gpt-3.5-turbo` is inconsistent (pretty much the reason its cheap too)",
      "time": "08:50",
      "timestamp": "1683647424.003659",
      "is_reply": true
    },
    {
      "sender": "Rafal",
      "user_id": "U023S84DFDJ",
      "message": "@joshbronko can you attach a original doc or add a link to the project?",
      "time": "09:15",
      "timestamp": "1683648913.372619",
      "is_reply": true
    },
    {
      "sender": "joshbronko",
      "user_id": "U031T0PNLUS",
      "message": "i never get this issue with ailabs",
      "time": "09:19",
      "timestamp": "1683649178.644779",
      "is_reply": true
    },
    {
      "sender": "joshbronko",
      "user_id": "U031T0PNLUS",
      "message": "its always been with aihub",
      "time": "09:19",
      "timestamp": "1683649183.656999",
      "is_reply": true
    },
    {
      "sender": "joshbronko",
      "user_id": "U031T0PNLUS",
      "message": "even with 4.0",
      "time": "09:20",
      "timestamp": "1683649204.478599",
      "is_reply": true
    },
    {
      "sender": "vineeth",
      "user_id": "U0175SZ13F0",
      "message": "Okay @Rafal dont you think this is because of RLHF? That why it politely says I’m sorry - however davinci was just meant for completion -> no RLHF",
      "time": "09:21",
      "timestamp": "1683649263.745689",
      "is_reply": true
    },
    {
      "sender": "vineeth",
      "user_id": "U0175SZ13F0",
      "message": "Sometimes alignment is not great :lolcry:",
      "time": "09:21",
      "timestamp": "1683649293.955379",
      "is_reply": true
    },
    {
      "sender": "joshbronko",
      "user_id": "U031T0PNLUS",
      "message": "",
      "time": "09:30",
      "timestamp": "1683649815.618869",
      "is_reply": true
    },
    {
      "sender": "Rafal",
      "user_id": "U023S84DFDJ",
      "message": "I think the completion endpoint is more eager to generate the output even if the prompt is unclear.\nRLHF models tend to put some disclaimer information in such cases.\nLet me modify the prompt wrapper to utilize this feedback and tell the model to not look for excuses and strictly answer the question\n\nI found that these prompts generate the JSON\n1. Please extract the essential information from the document and present it in a JSON format\n2. your task is to scan the document content and retrieve all key information in the JSON format. Output only a JSON with key: value pairs.",
      "time": "09:48",
      "timestamp": "1683650899.194849",
      "is_reply": true
    },
    {
      "sender": "vineeth",
      "user_id": "U0175SZ13F0",
      "message": "Also if you just add a markdown prompt of a json at the end like so ````json` the model just takes off from there",
      "time": "09:51",
      "timestamp": "1683651113.377139",
      "is_reply": true
    },
    {
      "sender": "vineeth",
      "user_id": "U0175SZ13F0",
      "message": "The above technique is something thats used extensively",
      "time": "09:53",
      "timestamp": "1683651181.463529",
      "is_reply": true
    },
    {
      "sender": "vineeth",
      "user_id": "U0175SZ13F0",
      "message": "You can already see how effective providing markdown hints can be (see below):",
      "time": "09:57",
      "timestamp": "1683651454.658309",
      "is_reply": true
    },
    {
      "sender": "Rafal",
      "user_id": "U023S84DFDJ",
      "message": "maybe we could add some heuristics to include these hints in the prompt if Json/Yaml question is detected? :thinking_face:\nI guess we shouldn’t expect the users to know these tricks",
      "time": "10:01",
      "timestamp": "1683651665.774169",
      "is_reply": true
    },
    {
      "sender": "vineeth",
      "user_id": "U0175SZ13F0",
      "message": "Yep definitely",
      "time": "10:01",
      "timestamp": "1683651691.426339",
      "is_reply": true
    },
    {
      "sender": "vineeth",
      "user_id": "U0175SZ13F0",
      "message": "Should be simple to add",
      "time": "10:01",
      "timestamp": "1683651698.906969",
      "is_reply": true
    },
    {
      "sender": "joshbronko",
      "user_id": "U031T0PNLUS",
      "message": "so what is different between the two engines?",
      "time": "10:29",
      "timestamp": "1683653384.383739",
      "is_reply": true
    },
    {
      "sender": "vineeth",
      "user_id": "U0175SZ13F0",
      "message": "The ones I sent above is the default chatgpt model, just changed the prompt",
      "time": "10:30",
      "timestamp": "1683653416.489659",
      "is_reply": true
    },
    {
      "sender": "vineeth",
      "user_id": "U0175SZ13F0",
      "message": "You can give it a go",
      "time": "10:30",
      "timestamp": "1683653429.984759",
      "is_reply": true
    },
    {
      "sender": "joshbronko",
      "user_id": "U031T0PNLUS",
      "message": "no im asking between aihub and labs",
      "time": "10:30",
      "timestamp": "1683653444.408739",
      "is_reply": true
    },
    {
      "sender": "joshbronko",
      "user_id": "U031T0PNLUS",
      "message": "the way we prompt the backend",
      "time": "10:30",
      "timestamp": "1683653449.538029",
      "is_reply": true
    },
    {
      "sender": "vineeth",
      "user_id": "U0175SZ13F0",
      "message": "Its not the prompt — there is difference in models",
      "time": "10:31",
      "timestamp": "1683653463.631469",
      "is_reply": true
    },
    {
      "sender": "vineeth",
      "user_id": "U0175SZ13F0",
      "message": "ailabs uses `text-davinci-003` which isnt RLHF trained while all the chat models (`gpt-3.5-turbo` , `gpt-4` ) are RLHF trained which are used in `aihub`",
      "time": "10:31",
      "timestamp": "1683653506.778369",
      "is_reply": true
    },
    {
      "sender": "joshbronko",
      "user_id": "U031T0PNLUS",
      "message": "makes sense",
      "time": "10:31",
      "timestamp": "1683653518.925209",
      "is_reply": true
    }
  ],
  "metadata": {
    "channel_id": "C0516UPPMT3",
    "channel_name": "aihub-feedback",
    "date_file": "2023-05-09.json",
    "message_count": 35,
    "start_time": "1683643278.181429",
    "end_time": "1683653518.925209",
    "is_thread": true
  }
}