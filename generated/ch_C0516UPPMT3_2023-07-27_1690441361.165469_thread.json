{
  "id": "ch_C0516UPPMT3_2023-07-27_1690441361.165469_thread",
  "type": "channel",
  "channel_name": "aihub-feedback",
  "conversation_type": "thread",
  "participants": [
    "Vishnu",
    "vineeth",
    "lydia",
    "Sławek Biel"
  ],
  "messages": [
    {
      "sender": "Sławek Biel",
      "user_id": "U03E1LBTKV2",
      "message": "Ok, I see it sets `input_record` parameter and so does our refiner script template. But I don’t see any code that uses this parameter.\n@vineeth do you know ?",
      "time": "00:02",
      "timestamp": "1690441361.165469",
      "is_reply": false
    },
    {
      "sender": "vineeth",
      "user_id": "U0175SZ13F0",
      "message": "We always use the first record since all the converse / build mode maps the entire doc as single record, if we are doing split classification that means it just considers the first record.",
      "time": "00:03",
      "timestamp": "1690441431.000459",
      "is_reply": true
    },
    {
      "sender": "lydia",
      "user_id": "UJK4LKYSJ",
      "message": "@vineeth this will be a problem for the LLMs in Refiner capability we’re releasing in 23.07. Can you give an estimate of how much work it’ll take to properly handle records?\n\ncc @hannah this will be a blocker for sol eng use",
      "time": "06:59",
      "timestamp": "1690466386.381109",
      "is_reply": true
    },
    {
      "sender": "Vishnu",
      "user_id": "U02RY7NLQMN",
      "message": "for context what we are trying to achieve is - we want *all* occurrences of field A. if the document is long, the occurrences will exceed the top K chunks fetched by aihub. so we are trying to split every document into chunk-sized records and map the prompt on each record and combine back together.",
      "time": "07:05",
      "timestamp": "1690466720.411309",
      "is_reply": true
    },
    {
      "sender": "lydia",
      "user_id": "UJK4LKYSJ",
      "message": "Btw, I was not able to reproduce this on my W2 and Fedloan docs (i have some files where I combine multiple W2/Fedloans together, so the file has 4-5 records). Do you know if this is only triggered on long docs?",
      "time": "08:13",
      "timestamp": "1690470810.726209",
      "is_reply": true
    },
    {
      "sender": "vineeth",
      "user_id": "U0175SZ13F0",
      "message": "> @vineeth this will be a problem for the LLMs in Refiner capability we’re releasing in 23.07. Can you give an estimate of how much work it’ll take to properly handle records?\n@lydia sure will discuss this with Hari once he’s back and get back to you with estimates",
      "time": "08:14",
      "timestamp": "1690470869.886349",
      "is_reply": true
    }
  ],
  "metadata": {
    "channel_id": "C0516UPPMT3",
    "channel_name": "aihub-feedback",
    "date_file": "2023-07-27.json",
    "message_count": 6,
    "start_time": "1690441361.165469",
    "end_time": "1690470869.886349",
    "is_thread": true
  }
}