{
  "id": "ch_C0516UPPMT3_2023-09-19_1695137360.660039_thread",
  "type": "channel",
  "channel_name": "aihub-feedback",
  "conversation_type": "thread",
  "participants": [
    "Bastiane",
    "lydia",
    "Travis",
    "Bas"
  ],
  "messages": [
    {
      "sender": "lydia",
      "user_id": "UJK4LKYSJ",
      "message": "@Bas are you using basic or complex prompt?",
      "time": "08:29",
      "timestamp": "1695137360.660039",
      "is_reply": false
    },
    {
      "sender": "Bas",
      "user_id": "U0290LSC5QA",
      "message": "@lydia I tried every possible variation of complex and basic prompt in many different types of questions",
      "time": "08:33",
      "timestamp": "1695137633.012729",
      "is_reply": true
    },
    {
      "sender": "Travis",
      "user_id": "U017E5NNKAP",
      "message": "Would adding an LLM prompt with refiner be something to explore?",
      "time": "08:57",
      "timestamp": "1695139061.270469",
      "is_reply": true
    },
    {
      "sender": "Travis",
      "user_id": "U017E5NNKAP",
      "message": "Or possibly a refiner interface in the prompts of build?",
      "time": "08:58",
      "timestamp": "1695139135.529729",
      "is_reply": true
    },
    {
      "sender": "Bas",
      "user_id": "U0290LSC5QA",
      "message": "Great suggestions @Travis. I include here screenshots of a few different approaches I took - but results are very unpredictable",
      "time": "09:01",
      "timestamp": "1695139310.253489",
      "is_reply": true
    },
    {
      "sender": "Travis",
      "user_id": "U017E5NNKAP",
      "message": "I’ve had similar frustrations in the output not being a consistent format. I feel like there’s a point where you’re at the mercy of what LLM will output, thus we could benefit from a downstream transfer function more often than not.",
      "time": "09:12",
      "timestamp": "1695139934.522309",
      "is_reply": true
    },
    {
      "sender": "Bastiane",
      "user_id": "U046R81BMM4",
      "message": "@Bas did you try switching to simple prompt mode?",
      "time": "10:01",
      "timestamp": "1695142863.548849",
      "is_reply": true
    },
    {
      "sender": "Bas",
      "user_id": "U0290LSC5QA",
      "message": "yes, simple, complex, all multiple variations. I included the screenshots in the pdf above",
      "time": "10:05",
      "timestamp": "1695143138.010149",
      "is_reply": true
    },
    {
      "sender": "Bastiane",
      "user_id": "U046R81BMM4",
      "message": "oh I missed your first page, only saw the screenshots for complex mode. So the simple mode seems to work but only for one document? We are working on improving the backend pipeline to address this issue",
      "time": "10:22",
      "timestamp": "1695144158.025379",
      "is_reply": true
    },
    {
      "sender": "Bas",
      "user_id": "U0290LSC5QA",
      "message": "Yes, it works for some and then not for others. It feels unpredictable why it does it one way or another. But @Travis is correct that it is equally unpredictable what I really want as a user.\n\nAn LLM based way to use refiner could be a solution. For instance (and this is just for Build):\n\n• When my prompt include the words 'total', 'amount', 'cost' or other similar wording: the LLM should respond with 'it looks like you're looking for a number - do you want your app to return just the number?' \n• Or if the answer includes a number - similar LLM response \"the response to this prompt includes a number - do you want just the number or the rich response?\"\n• \"the response to this prompt includes a number that looks like a monetary value - do you want to include the currency in your app?\"\n• \"It seems like you're looking for a date - do you have a preferred format?\"\nWhen I'm building an app based on one doc, I may want more control over the output. And while I can put refinement in the original prompt itself, I may not be aware I can do that, and it is still unpredictable that it will behave similarly for all other docs",
      "time": "11:16",
      "timestamp": "1695147406.245719",
      "is_reply": true
    }
  ],
  "metadata": {
    "channel_id": "C0516UPPMT3",
    "channel_name": "aihub-feedback",
    "date_file": "2023-09-19.json",
    "message_count": 10,
    "start_time": "1695137360.660039",
    "end_time": "1695147406.245719",
    "is_thread": true
  }
}