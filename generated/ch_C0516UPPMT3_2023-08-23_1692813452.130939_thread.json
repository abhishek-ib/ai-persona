{
  "id": "ch_C0516UPPMT3_2023-08-23_1692813452.130939_thread",
  "type": "channel",
  "channel_name": "aihub-feedback",
  "conversation_type": "thread",
  "participants": [
    "JD",
    "Heymian",
    "Matt Weaver",
    "peter"
  ],
  "messages": [
    {
      "sender": "Matt Weaver",
      "user_id": "U01B8GFNUAC",
      "message": "Hey, I think the answer is yes, but just to confirm,.... will InstaLLM be supported for customer private cloud hosted deployments of Instabase?",
      "time": "10:57",
      "timestamp": "1692813452.130939",
      "is_reply": false
    },
    {
      "sender": "peter",
      "user_id": "U02NAREL9L7",
      "message": "cc @Clemens",
      "time": "11:38",
      "timestamp": "1692815896.761229",
      "is_reply": true
    },
    {
      "sender": "JD",
      "user_id": "U02DXASL3U0",
      "message": "In speaking with Anant yesterday, the answer is \"yes\" -- it can be shipped as a large container, but the infra required on the customer side will be expensive.",
      "time": "12:33",
      "timestamp": "1692819213.209859",
      "is_reply": true
    },
    {
      "sender": "Heymian",
      "user_id": "UADQ9V8PK",
      "message": "Yes, weâ€™re looking into a cloud agnostic solution for hosting InstaLLM. The infra will be expensive on their end, and the hardware will potentially be very hard to come by, especially if performance comparable to openAI is desired. We ourselves have not been able to acquire A100 machines to use in AWS.",
      "time": "12:41",
      "timestamp": "1692819701.833119",
      "is_reply": true
    }
  ],
  "metadata": {
    "channel_id": "C0516UPPMT3",
    "channel_name": "aihub-feedback",
    "date_file": "2023-08-23.json",
    "message_count": 4,
    "start_time": "1692813452.130939",
    "end_time": "1692819701.833119",
    "is_thread": true
  }
}