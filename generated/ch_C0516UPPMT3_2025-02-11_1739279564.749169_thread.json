{
  "id": "ch_C0516UPPMT3_2025-02-11_1739279564.749169_thread",
  "type": "channel",
  "channel_name": "aihub-feedback",
  "conversation_type": "thread",
  "participants": [
    "jordy.vlan",
    "Nathaniel",
    "Hamish"
  ],
  "messages": [
    {
      "sender": "Hamish",
      "user_id": "U06G3LGDBQU",
      "message": "Hey team, ANZ have some questions about how we defend against prompt injection. The scenario they are worried for something like a mortgage origination use case is:\n\n_\"Crafting prompts around quietly overstating income and ignoring large expenses (perhaps white text on a white background). That way the customer is covered from the document, but we ‘accidentally’ transpose incorrect data. Mortgage statements have always been faked, but embedding commands within them is a new threat.\"_\n\n*Q: What controls does Instabase have to protect against prompt injection attacks within documents?*\n\ncc @jordy.vlan",
      "time": "05:12",
      "timestamp": "1739279564.749169",
      "is_reply": false
    },
    {
      "sender": "jordy.vlan",
      "user_id": "U072CDMB4N8",
      "message": "Tagging @vineeth as he investigated this in the past",
      "time": "05:31",
      "timestamp": "1739280669.678019",
      "is_reply": true
    },
    {
      "sender": "Nathaniel",
      "user_id": "U04BGHM4AEL",
      "message": "This isn't a full answer, but at least one aspect I can think of is that our `Treat files as images` setting should help against hidden, non-human readable text (like the white text on a white background).",
      "time": "10:18",
      "timestamp": "1739297918.789699",
      "is_reply": true
    }
  ],
  "metadata": {
    "channel_id": "C0516UPPMT3",
    "channel_name": "aihub-feedback",
    "date_file": "2025-02-11.json",
    "message_count": 3,
    "start_time": "1739279564.749169",
    "end_time": "1739297918.789699",
    "is_thread": true
  }
}